"""
Style analysis strategy.
"""

from typing import Dict, Any

from server.services.strategies.base import AnalysisStrategy
from server.core.analysis import StyleAnalyzer


class StyleAnalysisStrategy(AnalysisStrategy):
    """Strategy for style analysis."""

    def __init__(self):
        self.analyzer = StyleAnalyzer()

    async def analyze(
        self,
        text1_content: str,
        text2_content: str,
        params: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Perform style analysis.

        Args:
            text1_content: First text content
            text2_content: Second text content
            params: Analysis parameters

        Returns:
            Dictionary with similarity, interpretation, features
        """
        result = self.analyzer.compare_styles(text1_content, text2_content)

        # Build detailed report
        detailed_report = [
            f"âœï¸ Ğ¡Ñ‚Ğ¸Ğ»Ğ¸ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·",
            f"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•",
            f"",
            f"â–ª ĞĞ±Ñ‰Ğ°Ñ ÑÑ…Ğ¾Ğ¶ĞµÑÑ‚ÑŒ ÑÑ‚Ğ¸Ğ»Ñ: {result['style_similarity'] * 100:.1f}%",
            f"",
            f"â¤ Ğ˜Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚Ğ°Ñ†Ğ¸Ñ:",
            f"  {result['interpretation']}",
            f"",
            f"ğŸ“Š Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ ÑÑ‚Ğ¸Ğ»Ğ¸ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ¸ÑÑ‚Ğ¸Ğº:"
        ]

        # Add feature comparison - Ğ³Ñ€ÑƒĞ¿Ğ¿Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿Ğ¾ Ñ‚Ğ¸Ğ¿Ğ°Ğ¼
        if 'feature_similarities' in result:
            # Ğ¡Ğ»Ğ¾Ğ²Ğ°Ñ€ÑŒ Ğ¿ĞµÑ€ĞµĞ²Ğ¾Ğ´Ğ°
            feature_names = {
                # Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¹
                'avg_sentence_length': 'Ğ¡Ñ€ĞµĞ´Ğ½ÑÑ Ğ´Ğ»Ğ¸Ğ½Ğ° Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ',
                'sentence_length_std': 'Ğ’Ğ°Ñ€Ğ¸Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ´Ğ»Ğ¸Ğ½Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¹',
                'max_sentence_length': 'ĞœĞ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ´Ğ»Ğ¸Ğ½Ğ° Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ',
                'min_sentence_length': 'ĞœĞ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ´Ğ»Ğ¸Ğ½Ğ° Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ',

                # Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° ÑĞ»Ğ¾Ğ²
                'avg_word_length': 'Ğ¡Ñ€ĞµĞ´Ğ½ÑÑ Ğ´Ğ»Ğ¸Ğ½Ğ° ÑĞ»Ğ¾Ğ²Ğ°',
                'word_length_std': 'Ğ’Ğ°Ñ€Ğ¸Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ´Ğ»Ğ¸Ğ½Ñ‹ ÑĞ»Ğ¾Ğ²',

                # Ğ‘Ğ¾Ğ³Ğ°Ñ‚ÑÑ‚Ğ²Ğ¾ ÑĞ»Ğ¾Ğ²Ğ°Ñ€Ñ
                'type_token_ratio': 'Ğ Ğ°Ğ·Ğ½Ğ¾Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¸Ğµ Ğ»ĞµĞºÑĞ¸ĞºĞ¸',
                'hapax_legomena_ratio': 'Ğ£Ğ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğµ ÑĞ»Ğ¾Ğ²Ğ°',

                # ĞŸÑƒĞ½ĞºÑ‚ÑƒĞ°Ñ†Ğ¸Ñ
                'comma_ratio': 'Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ·Ğ°Ğ¿ÑÑ‚Ñ‹Ñ…',
                'period_ratio': 'Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ‚Ğ¾Ñ‡ĞµĞº',
                'question_ratio': 'Ğ’Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ',
                'exclamation_ratio': 'Ğ’Ğ¾ÑĞºĞ»Ğ¸Ñ†Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ',
                'quote_ratio': 'Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ĞºĞ°Ğ²Ñ‹Ñ‡ĞµĞº',
                'dash_ratio': 'Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ‚Ğ¸Ñ€Ğµ',

                # Ğ”Ñ€ÑƒĞ³Ğ¾Ğµ
                'capital_ratio': 'Ğ—Ğ°Ğ³Ğ»Ğ°Ğ²Ğ½Ñ‹Ğµ Ğ±ÑƒĞºĞ²Ñ‹',
                'digit_ratio': 'Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ†Ğ¸Ñ„Ñ€'
            }

            # Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ¿Ğ¾ ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸ÑĞ¼
            detailed_report.append("")
            detailed_report.append("â–« Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¹:")
            for feature in ['avg_sentence_length', 'sentence_length_std', 'max_sentence_length', 'min_sentence_length']:
                if feature in result['feature_similarities']:
                    sim = result['feature_similarities'][feature]
                    name = feature_names.get(feature, feature)
                    detailed_report.append(f"    â€¢ {name}: {sim * 100:.1f}%")

            detailed_report.append("")
            detailed_report.append("â–« Ğ›ĞµĞºÑĞ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¾ÑĞ¾Ğ±ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸:")
            for feature in ['avg_word_length', 'word_length_std', 'type_token_ratio', 'hapax_legomena_ratio']:
                if feature in result['feature_similarities']:
                    sim = result['feature_similarities'][feature]
                    name = feature_names.get(feature, feature)
                    detailed_report.append(f"    â€¢ {name}: {sim * 100:.1f}%")

            detailed_report.append("")
            detailed_report.append("â–« ĞŸÑƒĞ½ĞºÑ‚ÑƒĞ°Ñ†Ğ¸Ñ:")
            for feature in ['comma_ratio', 'period_ratio', 'question_ratio', 'exclamation_ratio', 'quote_ratio', 'dash_ratio']:
                if feature in result['feature_similarities']:
                    sim = result['feature_similarities'][feature]
                    name = feature_names.get(feature, feature)
                    detailed_report.append(f"    â€¢ {name}: {sim * 100:.1f}%")

            detailed_report.append("")
            detailed_report.append("â–« ĞŸÑ€Ğ¾Ñ‡Ğ¸Ğµ Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ¸ÑÑ‚Ğ¸ĞºĞ¸:")
            for feature in ['capital_ratio', 'digit_ratio']:
                if feature in result['feature_similarities']:
                    sim = result['feature_similarities'][feature]
                    name = feature_names.get(feature, feature)
                    detailed_report.append(f"    â€¢ {name}: {sim * 100:.1f}%")

        detailed_report.extend([
            f"",
            f"â„¹ï¸ ĞœĞµÑ‚Ğ¾Ğ´Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°:",
            f"  â€¢ Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ 16 ÑÑ‚Ğ¸Ğ»Ğ¸ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¾Ğ²",
            f"  â€¢ Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹ Ñ‚ĞµĞºÑÑ‚Ğ°",
            f"  â€¢ ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¸ Ğ²Ğ·Ğ²ĞµÑˆĞµĞ½Ğ½Ğ¾Ğµ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº",
            f"  â€¢ ĞšĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½Ğ°Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ° Ğ°Ğ²Ñ‚Ğ¾Ñ€ÑĞºĞ¾Ğ³Ğ¾ ÑÑ‚Ğ¸Ğ»Ñ"
        ])

        return {
            "similarity": float(result['style_similarity']),
            "interpretation": "\n".join(detailed_report),
            "features": {
                "text1": result['features1'],
                "text2": result['features2']
            },
            "feature_similarities": result['feature_similarities']
        }

    def get_type(self) -> str:
        """Get analysis type identifier."""
        return "style"
