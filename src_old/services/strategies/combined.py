"""
Combined analysis strategy.
Combines multiple analysis strategies into one comprehensive result.
"""

from typing import Dict, Any, List

from server.services.strategies.base import AnalysisStrategy


class CombinedAnalysisStrategy(AnalysisStrategy):
    """Strategy for combined analysis using multiple strategies."""

    def __init__(self, strategies: Dict[str, AnalysisStrategy]):
        """
        Initialize combined strategy.

        Args:
            strategies: Dictionary of strategy_name -> strategy_instance
        """
        self.strategies = strategies

    async def analyze(
        self,
        text1_content: str,
        text2_content: str,
        params: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Perform combined analysis using multiple strategies.

        Args:
            text1_content: First text content
            text2_content: Second text content
            params: Analysis parameters including 'strategies' list and 'weights'

        Returns:
            Dictionary with results from all strategies and combined metrics
        """
        # Get list of strategies to run (include LLM by default for richer analysis)
        strategy_names = params.get("strategies", ["semantic", "style", "tfidf", "emotion"])

        # Default weights for each strategy (can be customized)
        default_weights = {
            "semantic": 0.35,   # Most important - captures meaning
            "style": 0.20,      # Important - captures writing style
            "tfidf": 0.15,      # Moderate - captures keywords
            "emotion": 0.15,    # Moderate - captures emotional tone
            "llm": 0.15         # Moderate - LLM-based deep analysis
        }

        weights = params.get("weights", default_weights)

        results = {}
        weighted_scores = []
        total_weight = 0

        # Run each strategy
        for strategy_name in strategy_names:
            if strategy_name in self.strategies:
                strategy = self.strategies[strategy_name]
                weight = weights.get(strategy_name, 1.0 / len(strategy_names))

                try:
                    result = await strategy.analyze(text1_content, text2_content, params)
                    results[strategy_name] = {
                        **result,
                        "weight": weight,
                        "weighted_score": result.get("similarity", 0) * weight
                    }

                    # Collect weighted scores
                    if "similarity" in result:
                        weighted_scores.append(result["similarity"] * weight)
                        total_weight += weight

                except Exception as e:
                    results[strategy_name] = {
                        "error": str(e),
                        "weight": weight,
                        "weighted_score": 0
                    }

        # Calculate combined metrics
        weighted_similarity = sum(weighted_scores) / total_weight if total_weight > 0 else 0

        # Calculate simple average for comparison
        simple_similarities = [r.get("similarity", 0) for r in results.values() if "similarity" in r]
        avg_similarity = sum(simple_similarities) / len(simple_similarities) if simple_similarities else 0

        # Build detailed interpretation
        strategy_names_ru = {
            "semantic": "Ğ¡ĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·",
            "style": "Ğ¡Ñ‚Ğ¸Ğ»Ğ¸ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·",
            "tfidf": "TF-IDF Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·",
            "emotion": "Ğ­Ğ¼Ğ¾Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·",
            "llm": "ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ˜Ğ˜"
        }

        interpretation_parts = [
            f"ğŸ” ĞšĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²",
            f"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•",
            f"",
            f"â–ª Ğ˜Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ğ°Ñ ÑÑ…Ğ¾Ğ¶ĞµÑÑ‚ÑŒ: {weighted_similarity * 100:.1f}%",
            f"",
            f"ğŸ“Š Ğ”ĞµÑ‚Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¿Ğ¾ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ°Ğ¼:"
        ]

        for name, result in results.items():
            if "error" not in result:
                score = result.get("similarity", 0)
                weight = result.get("weight", 0)
                contribution = score * weight
                ru_name = strategy_names_ru.get(name, name)
                interpretation_parts.append(f"")
                interpretation_parts.append(
                    f"â–« {ru_name}: {score * 100:.1f}%"
                )
                interpretation_parts.append(
                    f"    Ğ’ĞµÑ: {weight * 100:.0f}% â†’ Ğ’ĞºĞ»Ğ°Ğ´: {contribution * 100:.1f}%"
                )

        interpretation_parts.extend([
            f"",
            f"â¤ Ğ˜Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚Ğ°Ñ†Ğ¸Ñ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°:",
            f"  {self._get_combined_interpretation(weighted_similarity)}",
            f"",
            f"â„¹ï¸ ĞœĞµÑ‚Ğ¾Ğ´Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ:",
            f"  â€¢ Ğ’Ğ·Ğ²ĞµÑˆĞµĞ½Ğ½Ğ¾Ğµ ÑƒÑÑ€ĞµĞ´Ğ½ĞµĞ½Ğ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²",
            f"  â€¢ ĞŸÑ€Ğ¾ÑÑ‚Ğ¾Ğµ ÑÑ€ĞµĞ´Ğ½ĞµĞµ: {avg_similarity * 100:.1f}%",
            f"  â€¢ Ğ£Ñ‡Ñ‘Ñ‚ Ğ²Ğ°Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ°",
            f"  â€¢ ĞšĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½Ğ°Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ° ÑÑ…Ğ¾Ğ¶ĞµÑÑ‚Ğ¸"
        ])

        return {
            "results": results,
            "similarity": float(weighted_similarity),  # Main similarity score
            "combined_similarity": float(weighted_similarity),
            "average_similarity": float(avg_similarity),
            "interpretation": "\n".join(interpretation_parts),
            "strategies_used": strategy_names,
            "weights_used": {k: v for k, v in weights.items() if k in strategy_names},
            "total_weight": total_weight
        }

    def _get_combined_interpretation(self, similarity: float) -> str:
        """Get interpretation for combined similarity score."""
        if similarity >= 0.9:
            return "Ğ¢ĞµĞºÑÑ‚Ñ‹ Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¸Ğ´ĞµĞ½Ñ‚Ğ¸Ñ‡Ğ½Ñ‹ Ğ¿Ğ¾ Ğ²ÑĞµĞ¼ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ°Ğ¼"
        elif similarity >= 0.75:
            return "ĞÑ‡ĞµĞ½ÑŒ Ğ²Ñ‹ÑĞ¾ĞºĞ°Ñ ÑÑ…Ğ¾Ğ¶ĞµÑÑ‚ÑŒ - Ñ‚ĞµĞºÑÑ‚Ñ‹ ÑĞ²Ğ½Ğ¾ ÑĞ²ÑĞ·Ğ°Ğ½Ñ‹"
        elif similarity >= 0.6:
            return "Ğ’Ñ‹ÑĞ¾ĞºĞ°Ñ ÑÑ…Ğ¾Ğ¶ĞµÑÑ‚ÑŒ - Ğ·Ğ°Ğ¼ĞµÑ‚Ğ½Ğ¾Ğµ ÑÑ…Ğ¾Ğ´ÑÑ‚Ğ²Ğ¾ Ğ¿Ğ¾ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğ½ÑÑ‚Ğ²Ñƒ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ²"
        elif similarity >= 0.45:
            return "Ğ£Ğ¼ĞµÑ€ĞµĞ½Ğ½Ğ°Ñ ÑÑ…Ğ¾Ğ¶ĞµÑÑ‚ÑŒ - ĞµÑÑ‚ÑŒ Ğ¾Ğ±Ñ‰Ğ¸Ğµ Ñ‡ĞµÑ€Ñ‚Ñ‹"
        elif similarity >= 0.3:
            return "ĞĞ¸Ğ·ĞºĞ°Ñ ÑÑ…Ğ¾Ğ¶ĞµÑÑ‚ÑŒ - Ğ¼Ğ°Ğ»Ğ¾ Ğ¾Ğ±Ñ‰ĞµĞ³Ğ¾"
        else:
            return "Ğ¢ĞµĞºÑÑ‚Ñ‹ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ°ÑÑ‚ÑÑ"

    def get_type(self) -> str:
        """Get analysis type identifier."""
        return "combined"
