"""
TF-IDF analysis strategy.
"""

from typing import Dict, Any

from server.services.strategies.base import AnalysisStrategy
from server.core.analysis import TFIDFAnalyzer


class TFIDFAnalysisStrategy(AnalysisStrategy):
    """Strategy for TF-IDF analysis."""

    def __init__(self):
        self.analyzer = TFIDFAnalyzer()

    async def analyze(
        self,
        text1_content: str,
        text2_content: str,
        params: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Perform TF-IDF analysis.

        Args:
            text1_content: First text content
            text2_content: Second text content
            params: Analysis parameters

        Returns:
            Dictionary with similarity, interpretation, top_words
        """
        result = self.analyzer.compare_texts(text1_content, text2_content)

        # Build detailed report
        detailed_report = [
            f"ðŸ“Š TF-IDF Ð°Ð½Ð°Ð»Ð¸Ð·",
            f"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•",
            f"",
            f"â–ª Ð¡Ñ…Ð¾Ð¶ÐµÑÑ‚ÑŒ Ð¿Ð¾ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ð¼ ÑÐ»Ð¾Ð²Ð°Ð¼: {result['tfidf_similarity'] * 100:.1f}%",
            f"â–ª ÐŸÐµÑ€ÐµÑÐµÑ‡ÐµÐ½Ð¸Ðµ ÑÐ»Ð¾Ð²Ð°Ñ€Ñ: {result['vocabulary_overlap'] * 100:.1f}%",
            f"",
            f"âž¤ Ð˜Ð½Ñ‚ÐµÑ€Ð¿Ñ€ÐµÑ‚Ð°Ñ†Ð¸Ñ:",
            f"  {result['interpretation']}",
            f"",
            f"ðŸ“‹ Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° ÑÐ»Ð¾Ð²Ð°Ñ€ÐµÐ¹:",
            f"  â€¢ Ð£Ð½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ñ… ÑÐ»Ð¾Ð² Ð² Ñ‚ÐµÐºÑÑ‚Ðµ 1: {result['vocab_size_1']}",
            f"  â€¢ Ð£Ð½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ñ… ÑÐ»Ð¾Ð² Ð² Ñ‚ÐµÐºÑÑ‚Ðµ 2: {result['vocab_size_2']}",
            f"  â€¢ ÐžÐ±Ñ‰Ð¸Ñ… ÑÐ»Ð¾Ð²: {result['shared_vocab']}",
            f"",
            f"â–« Ð¢Ð¾Ð¿-10 ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ñ… ÑÐ»Ð¾Ð² Ñ‚ÐµÐºÑÑ‚Ð° 1:"
        ]

        # Add top words for text 1
        for i, word_info in enumerate(result['top_words_text1'][:10], 1):
            if isinstance(word_info, dict):
                word, score = word_info['word'], word_info['score']
            else:
                word, score = word_info
            detailed_report.append(f"  {i}. {word} (Ð²ÐµÑ: {score:.3f})")

        detailed_report.append(f"")
        detailed_report.append(f"â–« Ð¢Ð¾Ð¿-10 ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ñ… ÑÐ»Ð¾Ð² Ñ‚ÐµÐºÑÑ‚Ð° 2:")

        # Add top words for text 2
        for i, word_info in enumerate(result['top_words_text2'][:10], 1):
            if isinstance(word_info, dict):
                word, score = word_info['word'], word_info['score']
            else:
                word, score = word_info
            detailed_report.append(f"  {i}. {word} (Ð²ÐµÑ: {score:.3f})")

        detailed_report.extend([
            f"",
            f"â„¹ï¸ ÐœÐµÑ‚Ð¾Ð´ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°:",
            f"  â€¢ TF-IDF (Term Frequency - Inverse Document Frequency)",
            f"  â€¢ Ð’Ñ‹ÑÐ²Ð»ÐµÐ½Ð¸Ðµ Ð²Ð°Ð¶Ð½Ñ‹Ñ… ÑÐ»Ð¾Ð² Ñ‡ÐµÑ€ÐµÐ· Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð½Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð·",
            f"  â€¢ ÐšÐ¾ÑÐ¸Ð½ÑƒÑÐ½Ð°Ñ ÑÑ…Ð¾Ð¶ÐµÑÑ‚ÑŒ TF-IDF Ð²ÐµÐºÑ‚Ð¾Ñ€Ð¾Ð²"
        ])

        return {
            "similarity": float(result['tfidf_similarity']),
            "interpretation": "\n".join(detailed_report),
            "vocabulary_overlap": result['vocabulary_overlap'],
            "top_words_text1": result['top_words_text1'],
            "top_words_text2": result['top_words_text2'],
            "vocab_size_1": result['vocab_size_1'],
            "vocab_size_2": result['vocab_size_2'],
            "shared_vocab": result['shared_vocab']
        }

    def get_type(self) -> str:
        """Get analysis type identifier."""
        return "tfidf"
