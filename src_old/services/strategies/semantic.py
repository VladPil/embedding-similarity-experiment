"""
Semantic analysis strategy using embeddings.
"""

from typing import Dict, Any

from server.services.strategies.base import AnalysisStrategy
from server.services.embedding_service import EmbeddingService
from server.core.similarity_calc import SimilarityCalculator


class SemanticAnalysisStrategy(AnalysisStrategy):
    """Strategy for semantic analysis using embeddings."""

    def __init__(self, embedding_service: EmbeddingService):
        self.embedding_service = embedding_service
        self.similarity_calc = SimilarityCalculator()

    async def analyze(
        self,
        text1_content: str,
        text2_content: str,
        params: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Perform semantic similarity analysis.

        Args:
            text1_content: First text content
            text2_content: Second text content
            params: Analysis parameters including text1_id, text2_id, model

        Returns:
            Dictionary with similarity, interpretation, model_used, dimensions
        """
        model_key = params.get("model", "multilingual-e5-base")

        # Get embeddings
        text1_id = params.get("text1_id")
        text2_id = params.get("text2_id")

        emb1 = await self.embedding_service.get_embedding(text1_id, model_key)
        emb2 = await self.embedding_service.get_embedding(text2_id, model_key)

        if emb1 is None or emb2 is None:
            raise ValueError("Failed to generate embeddings")

        # Calculate similarity
        similarity = self.similarity_calc.cosine_similarity(emb1, emb2)
        base_interpretation = self.similarity_calc.similarity_interpretation(similarity)

        # Build detailed report
        detailed_report = [
            f"ðŸ“Š Ð¡ÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð·",
            f"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•",
            f"",
            f"â–ª ÐžÐ±Ñ‰Ð°Ñ ÑÑ…Ð¾Ð¶ÐµÑÑ‚ÑŒ: {similarity * 100:.1f}%",
            f"",
            f"âž¤ Ð˜Ð½Ñ‚ÐµÑ€Ð¿Ñ€ÐµÑ‚Ð°Ñ†Ð¸Ñ:",
            f"  {base_interpretation}",
            f"",
            f"ðŸ“‹ Ð”ÐµÑ‚Ð°Ð»Ð¸ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°:",
            f"  â€¢ ÐœÐµÑ‚Ð¾Ð´: ÐšÐ¾ÑÐ¸Ð½ÑƒÑÐ½Ð¾Ðµ Ñ€Ð°ÑÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Ð²ÐµÐºÑ‚Ð¾Ñ€Ð¾Ð²",
            f"  â€¢ ÐœÐ¾Ð´ÐµÐ»ÑŒ: {model_key}",
            f"  â€¢ Ð Ð°Ð·Ð¼ÐµÑ€Ð½Ð¾ÑÑ‚ÑŒ: {len(emb1)} Ð¸Ð·Ð¼ÐµÑ€ÐµÐ½Ð¸Ð¹",
            f"  â€¢ Ð¢Ð¸Ð¿: Ð¡ÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð¸",
            f"",
            f"ðŸ“Š Ð¨ÐºÐ°Ð»Ð° Ð¾Ñ†ÐµÐ½ÐºÐ¸:",
            f"  â€¢ 90-100% - ÐŸÑ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð¸Ð´ÐµÐ½Ñ‚Ð¸Ñ‡Ð½Ñ‹Ðµ Ñ‚ÐµÐºÑÑ‚Ñ‹",
            f"  â€¢ 70-89% - ÐžÑ‡ÐµÐ½ÑŒ Ð¿Ð¾Ñ…Ð¾Ð¶Ð¸Ðµ Ð¿Ð¾ ÑÐ¼Ñ‹ÑÐ»Ñƒ",
            f"  â€¢ 50-69% - Ð£Ð¼ÐµÑ€ÐµÐ½Ð½Ð°Ñ ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ ÑÑ…Ð¾Ð¶ÐµÑÑ‚ÑŒ",
            f"  â€¢ 30-49% - Ð¡Ð»Ð°Ð±Ð°Ñ ÑÐ²ÑÐ·ÑŒ Ð¿Ð¾ ÑÐ¼Ñ‹ÑÐ»Ñƒ",
            f"  â€¢ 0-29% - Ð¢ÐµÐºÑÑ‚Ñ‹ Ð¿Ñ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð½Ðµ ÑÐ²ÑÐ·Ð°Ð½Ñ‹"
        ]

        return {
            "similarity": float(similarity),
            "interpretation": "\n".join(detailed_report),
            "model_used": model_key,
            "dimensions": len(emb1)
        }

    def get_type(self) -> str:
        """Get analysis type identifier."""
        return "semantic"
