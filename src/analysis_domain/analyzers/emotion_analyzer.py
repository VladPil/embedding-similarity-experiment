"""
–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –æ–∫—Ä–∞—Å–∫–∏ —Ç–µ–∫—Å—Ç–∞
"""
import json
from typing import Optional, Dict, Any
from loguru import logger

from src.text_domain.entities.base_text import BaseText
from src.text_domain.entities.chunking_strategy import ChunkingStrategy
from ..entities.base_analyzer import BaseAnalyzer
from ..entities.analysis_result import AnalysisResult
from src.common.types import AnalysisMode
from src.common.exceptions import AnalysisError


class EmotionAnalyzer(BaseAnalyzer):
    """
    –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –æ–∫—Ä–∞—Å–∫–∏ –∏ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞
    """

    def __init__(self, llm_service=None):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è"""
        self.llm_service = llm_service

    @property
    def name(self) -> str:
        return "emotion"

    @property
    def display_name(self) -> str:
        return "–ê–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–π"

    @property
    def description(self) -> str:
        return "–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—É—é –æ–∫—Ä–∞—Å–∫—É –∏ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞"

    @property
    def requires_llm(self) -> bool:
        return True

    async def analyze(
        self,
        text: BaseText,
        mode: AnalysisMode = AnalysisMode.FULL_TEXT,
        chunking_strategy: Optional[ChunkingStrategy] = None,
        context: Optional[Dict[str, Any]] = None
    ) -> AnalysisResult:
        """–ê–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–π"""
        try:
            import time
            start_time = time.time()

            content = await text.get_content()
            analysis_text = content[:3000]

            # –ú–æ–∫-–¥–∞–Ω–Ω—ã–µ (TODO: —Ä–µ–∞–ª—å–Ω—ã–π LLM)
            result_data = {
                "dominant_emotion": "–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è",
                "emotions": {
                    "—Ä–∞–¥–æ—Å—Ç—å": 0.2,
                    "–≥—Ä—É—Å—Ç—å": 0.1,
                    "–≥–Ω–µ–≤": 0.05,
                    "—Å—Ç—Ä–∞—Ö": 0.1,
                    "—É–¥–∏–≤–ª–µ–Ω–∏–µ": 0.15,
                },
                "sentiment": "–Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π",
                "sentiment_score": 0.55,  # 0-1
            }

            execution_time = (time.time() - start_time) * 1000

            result = AnalysisResult(
                text_id=text.id,
                analyzer_name=self.name,
                data=result_data,
                execution_time_ms=execution_time,
                mode=mode.value,
            )

            result.interpretation = self.interpret_results(result)
            return result

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —ç–º–æ—Ü–∏–π: {e}")
            raise AnalysisError(f"Emotion analysis failed: {e}")

    def interpret_results(self, result: AnalysisResult) -> str:
        """–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è"""
        data = result.data
        dominant = data.get("dominant_emotion", "–Ω/–¥")
        sentiment = data.get("sentiment", "–Ω/–¥")
        emotions = data.get("emotions", {})

        lines = [
            f"üòä –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑:",
            f"–î–æ–º–∏–Ω–∏—Ä—É—é—â–∞—è —ç–º–æ—Ü–∏—è: {dominant}",
            f"–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: {sentiment}",
            "\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —ç–º–æ—Ü–∏–π:"
        ]

        for emotion, score in sorted(emotions.items(), key=lambda x: x[1], reverse=True):
            lines.append(f"- {emotion}: {score:.0%}")

        return "\n".join(lines)
