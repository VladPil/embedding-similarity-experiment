"""
–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Ç–µ–º–ø–∞ –ø–æ–≤–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è (pace)
"""
from typing import Dict, Any, List
from loguru import logger

from ..entities.base_analyzer import BaseAnalyzer
from ..entities.analysis_result import AnalysisResult
from ..helpers.chunk_indexer import ChunkIndexer
from src.text_domain.entities.base_text import BaseText
from src.common.types import AnalysisMode
from src.common.exceptions import AnalysisError


class PaceAnalyzer(BaseAnalyzer):
    """
    –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Ç–µ–º–ø–∞ –ø–æ–≤–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è

    –ù–ï –¢–†–ï–ë–£–ï–¢ LLM - –æ—á–µ–Ω—å –±—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑!

    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç:
    - –ü–ª–æ—Ç–Ω–æ—Å—Ç—å —Å–æ–±—ã—Ç–∏–π (event density)
    - –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –¥–∏–∞–ª–æ–≥–æ–≤
    - –î–ª–∏–Ω—É –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
    - –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–µ–π—Å—Ç–≤–∏–π

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
    - –û–±—â–∏–π —Ç–µ–º–ø (slow/medium/fast)
    - –°–∫–æ—Ä —Ç–µ–º–ø–∞ (0-10)
    - Timeline —Ç–µ–º–ø–∞
    - –°—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    """

    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ —Ç–µ–º–ø–∞"""
        self.indexer = ChunkIndexer()

    @property
    def requires_llm(self) -> bool:
        """–ù–ï —Ç—Ä–µ–±—É–µ—Ç—Å—è LLM"""
        return False

    @property
    def requires_embeddings(self) -> bool:
        """–ù–µ —Ç—Ä–µ–±—É—é—Ç—Å—è embeddings"""
        return False

    async def analyze(
        self,
        text: BaseText,
        mode: AnalysisMode,
        **kwargs
    ) -> AnalysisResult:
        """
        –í—ã–ø–æ–ª–Ω–∏—Ç—å –∞–Ω–∞–ª–∏–∑ —Ç–µ–º–ø–∞

        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            mode: –†–µ–∂–∏–º –∞–Ω–∞–ª–∏–∑–∞
            **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã

        Returns:
            AnalysisResult: –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
        """
        try:
            logger.info(f"–ù–∞—á–∞–ª–æ –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–º–ø–∞: {text.title}")

            # –ü–æ–ª—É—á–∞–µ–º —á–∞–Ω–∫–∏
            chunks = kwargs.get('chunks', [])
            if not chunks:
                raise AnalysisError(
                    "–ê–Ω–∞–ª–∏–∑ —Ç–µ–º–ø–∞ —Ç—Ä–µ–±—É–µ—Ç —á–∞–Ω–∫–∏ —Ç–µ–∫—Å—Ç–∞",
                    details={"text_id": text.id}
                )

            # –í—ã—á–∏—Å–ª—è–µ–º —Ç–µ–º–ø –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —á–∞–Ω–∫–∞
            pace_scores = []

            for chunk in chunks:
                # –ü–ª–æ—Ç–Ω–æ—Å—Ç—å —Å–æ–±—ã—Ç–∏–π
                density = self.indexer._calculate_event_density(chunk.content)

                # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –¥–∏–∞–ª–æ–≥–æ–≤
                dialogue_ratio = self.indexer._calculate_dialogue_ratio(chunk.content)

                # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–∫–æ—Ä —Ç–µ–º–ø–∞
                pace_score = self._calculate_pace_score(density, dialogue_ratio)

                pace_scores.append({
                    "position": chunk.metadata.get('position_ratio', 0.0),
                    "score": pace_score,
                    "event_density": density,
                    "dialogue_ratio": dialogue_ratio
                })

            # –û–±—â–∏–π —Ç–µ–º–ø (–º–µ–¥–∏–∞–Ω–∞)
            scores_only = [p['score'] for p in pace_scores]
            overall_score = self._median(scores_only)

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ–π—Ç–∏–Ω–≥
            if overall_score < 4:
                pace_rating = "slow"
                pace_emoji = "üêå"
                pace_ru = "–º–µ–¥–ª–µ–Ω–Ω—ã–π"
            elif overall_score < 7:
                pace_rating = "medium"
                pace_emoji = "üö∂"
                pace_ru = "—Å—Ä–µ–¥–Ω–∏–π"
            else:
                pace_rating = "fast"
                pace_emoji = "üèÉ"
                pace_ru = "–±—ã—Å—Ç—Ä—ã–π"

            # Timeline (—Å–µ–º–ø–ª–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–µ 10% —Ç–µ–∫—Å—Ç–∞)
            timeline = self._create_timeline(pace_scores, sample_rate=0.1)

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            stats = self._calculate_statistics(pace_scores)

            logger.info(f"–¢–µ–º–ø: {pace_ru} ({overall_score:.1f}/10)")

            return AnalysisResult(
                analyzer_type=self.__class__.__name__,
                text_id=text.id,
                mode=mode,
                data={
                    "overall_pace": pace_rating,
                    "pace_emoji": pace_emoji,
                    "pace_ru": pace_ru,
                    "pace_score": round(overall_score, 2),
                    "timeline": timeline,
                    "statistics": stats
                }
            )

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–º–ø–∞: {e}")
            raise AnalysisError(
                f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–º–ø: {str(e)}",
                details={"text_id": text.id}
            )

    def _calculate_pace_score(self, event_density: float, dialogue_ratio: float) -> float:
        """
        –í—ã—á–∏—Å–ª–∏—Ç—å —Å–∫–æ—Ä —Ç–µ–º–ø–∞

        Args:
            event_density: –ü–ª–æ—Ç–Ω–æ—Å—Ç—å —Å–æ–±—ã—Ç–∏–π (0-1)
            dialogue_ratio: –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –¥–∏–∞–ª–æ–≥–æ–≤ (0-1)

        Returns:
            float: –°–∫–æ—Ä —Ç–µ–º–ø–∞ (0-10)
        """
        # –°–æ–±—ã—Ç–∏—è –≤–Ω–æ—Å—è—Ç 70%, –¥–∏–∞–ª–æ–≥–∏ 30%
        score = (event_density * 7.0) + (dialogue_ratio * 3.0)
        return min(score * 10, 10.0)

    def _median(self, values: List[float]) -> float:
        """–í—ã—á–∏—Å–ª–∏—Ç—å –º–µ–¥–∏–∞–Ω—É"""
        if not values:
            return 0.0

        sorted_values = sorted(values)
        n = len(sorted_values)

        if n % 2 == 0:
            return (sorted_values[n//2 - 1] + sorted_values[n//2]) / 2
        else:
            return sorted_values[n//2]

    def _create_timeline(
        self,
        pace_scores: List[Dict],
        sample_rate: float = 0.1
    ) -> List[Dict]:
        """
        –°–æ–∑–¥–∞—Ç—å timeline —Ç–µ–º–ø–∞

        Args:
            pace_scores: –í—Å–µ —Å–∫–æ—Ä—ã —Ç–µ–º–ø–∞
            sample_rate: –ß–∞—Å—Ç–æ—Ç–∞ —Å–µ–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏—è (0-1)

        Returns:
            List[Dict]: Timeline
        """
        if not pace_scores:
            return []

        # –°–µ–º–ø–ª–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã
        step = max(int(len(pace_scores) * sample_rate), 1)
        timeline = []

        for i in range(0, len(pace_scores), step):
            sample = pace_scores[i]
            timeline.append({
                "position": sample['position'],
                "pace": round(sample['score'], 2)
            })

        return timeline

    def _calculate_statistics(self, pace_scores: List[Dict]) -> Dict:
        """
        –í—ã—á–∏—Å–ª–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ç–µ–º–ø–∞

        Args:
            pace_scores: –í—Å–µ —Å–∫–æ—Ä—ã —Ç–µ–º–ø–∞

        Returns:
            Dict: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        """
        if not pace_scores:
            return {}

        scores = [p['score'] for p in pace_scores]
        event_densities = [p['event_density'] for p in pace_scores]
        dialogue_ratios = [p['dialogue_ratio'] for p in pace_scores]

        return {
            "min_pace": round(min(scores), 2),
            "max_pace": round(max(scores), 2),
            "avg_pace": round(sum(scores) / len(scores), 2),
            "median_pace": round(self._median(scores), 2),
            "avg_event_density": round(sum(event_densities) / len(event_densities), 2),
            "avg_dialogue_ratio": round(sum(dialogue_ratios) / len(dialogue_ratios), 2),
            "pace_variance": round(self._variance(scores), 2)
        }

    def _variance(self, values: List[float]) -> float:
        """–í—ã—á–∏—Å–ª–∏—Ç—å –¥–∏—Å–ø–µ—Ä—Å–∏—é"""
        if not values:
            return 0.0

        mean = sum(values) / len(values)
        return sum((x - mean) ** 2 for x in values) / len(values)

    def interpret_results(self, result: AnalysisResult) -> str:
        """
        –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞

        Args:
            result: –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞

        Returns:
            str: –ß–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è
        """
        data = result.data
        pace_rating = data.get('overall_pace', 'unknown')
        pace_score = data.get('pace_score', 0)
        pace_emoji = data.get('pace_emoji', 'üìä')
        pace_ru = data.get('pace_ru', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π')
        stats = data.get('statistics', {})

        lines = [
            f"üèÉ **–ê–Ω–∞–ª–∏–∑ —Ç–µ–º–ø–∞ –ø–æ–≤–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è**\n",
            f"{pace_emoji} **–û–±—â–∏–π —Ç–µ–º–ø**: {pace_ru} ({pace_score:.1f}/10)\n"
        ]

        # –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è
        if pace_rating == "fast":
            interpretation = (
                "–ë—ã—Å—Ç—Ä—ã–π —Ç–µ–º–ø –ø–æ–≤–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è. –ú–Ω–æ–≥–æ –¥–µ–π—Å—Ç–≤–∏–π, –¥–∏–Ω–∞–º–∏—á–Ω—ã–µ —Å—Ü–µ–Ω—ã, "
                "–∫–æ—Ä–æ—Ç–∫–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è. –î–µ—Ä–∂–∏—Ç —á–∏—Ç–∞—Ç–µ–ª—è –≤ –Ω–∞–ø—Ä—è–∂–µ–Ω–∏–∏."
            )
        elif pace_rating == "medium":
            interpretation = (
                "–°—Ä–µ–¥–Ω–∏–π —Ç–µ–º–ø –ø–æ–≤–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è. –•–æ—Ä–æ—à–∏–π –±–∞–ª–∞–Ω—Å –º–µ–∂–¥—É –¥–µ–π—Å—Ç–≤–∏–µ–º "
                "–∏ –æ–ø–∏—Å–∞–Ω–∏—è–º–∏. –ö–æ–º—Ñ–æ—Ä—Ç–Ω–æ–µ —á—Ç–µ–Ω–∏–µ."
            )
        else:
            interpretation = (
                "–ú–µ–¥–ª–µ–Ω–Ω—ã–π —Ç–µ–º–ø –ø–æ–≤–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è. –ú–Ω–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏–π, —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏–π, "
                "–∞—Ç–º–æ—Å—Ñ–µ—Ä–Ω—ã—Ö —Å—Ü–µ–Ω. –§–æ–∫—É—Å –Ω–∞ –¥–µ—Ç–∞–ª—è—Ö."
            )

        lines.append(f"üí° **–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è**: {interpretation}\n")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        if stats:
            lines.append(f"üìä **–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞**:")
            lines.append(f"   ‚Ä¢ –ú–∏–Ω. —Ç–µ–º–ø: {stats.get('min_pace', 0)}/10")
            lines.append(f"   ‚Ä¢ –ú–∞–∫—Å. —Ç–µ–º–ø: {stats.get('max_pace', 0)}/10")
            lines.append(f"   ‚Ä¢ –°—Ä–µ–¥–Ω–∏–π: {stats.get('avg_pace', 0)}/10")
            lines.append(f"   ‚Ä¢ –ü–ª–æ—Ç–Ω–æ—Å—Ç—å —Å–æ–±—ã—Ç–∏–π: {stats.get('avg_event_density', 0):.2f}")
            lines.append(f"   ‚Ä¢ –î–æ–ª—è –¥–∏–∞–ª–æ–≥–æ–≤: {stats.get('avg_dialogue_ratio', 0):.2f}")

        return '\n'.join(lines)
