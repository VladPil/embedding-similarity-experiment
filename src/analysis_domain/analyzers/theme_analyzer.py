"""
ÐÐ½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€ Ñ‚ÐµÐ¼ Ð¿Ñ€Ð¾Ð¸Ð·Ð²ÐµÐ´ÐµÐ½Ð¸Ñ
"""
import json
import re
from typing import Dict, Any, List, Optional
from loguru import logger

from ..entities.base_analyzer import BaseAnalyzer
from ..entities.analysis_result import AnalysisResult
from ..entities.prompt_template import PromptTemplate
from src.text_domain.entities.base_text import BaseText
from src.common.types import AnalysisMode
from src.common.exceptions import AnalysisError


class ThemeAnalyzer(BaseAnalyzer):
    """
    ÐÐ½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€ Ð¾ÑÐ½Ð¾Ð²Ð½Ñ‹Ñ… Ñ‚ÐµÐ¼ Ð¿Ñ€Ð¾Ð¸Ð·Ð²ÐµÐ´ÐµÐ½Ð¸Ñ

    Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚:
    - Ð¡ÐµÐ¼Ð¿Ð»Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ‡Ð°Ð½ÐºÐ¾Ð² (ÐºÐ°Ð¶Ð´Ñ‹Ð¹ 10-Ð¹)
    - LLM Ð´Ð»Ñ Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ñ Ñ‚ÐµÐ¼
    - ÐÐ³Ñ€ÐµÐ³Ð°Ñ†Ð¸ÑŽ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€ÑÑŽÑ‰Ð¸Ñ…ÑÑ Ñ‚ÐµÐ¼

    Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚:
    - Ð¡Ð¿Ð¸ÑÐ¾Ðº Ð¾ÑÐ½Ð¾Ð²Ð½Ñ‹Ñ… Ñ‚ÐµÐ¼
    - ÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ ÐºÐ°Ð¶Ð´Ð¾Ð¹ Ñ‚ÐµÐ¼Ñ‹
    - ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹ Ð¸Ð· Ñ‚ÐµÐºÑÑ‚Ð°
    - Ð§Ð°ÑÑ‚Ð¾Ñ‚Ñƒ Ð²ÑÑ‚Ñ€ÐµÑ‡Ð°ÐµÐ¼Ð¾ÑÑ‚Ð¸
    """

    def __init__(
        self,
        llm_service: Optional[Any] = None,
        prompt_template: Optional[PromptTemplate] = None,
        max_themes: int = 5,
        sample_chunks: int = 10
    ):
        """
        Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð° Ñ‚ÐµÐ¼

        Args:
            llm_service: Ð¡ÐµÑ€Ð²Ð¸Ñ Ð´Ð»Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ñ LLM
            prompt_template: Ð¨Ð°Ð±Ð»Ð¾Ð½ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ð°
            max_themes: ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ðµ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ñ‚ÐµÐ¼
            sample_chunks: ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ñ‡Ð°Ð½ÐºÐ¾Ð² Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°
        """
        self.llm_service = llm_service
        self.prompt_template = prompt_template or self._create_default_prompt()
        self.max_themes = max_themes
        self.sample_chunks = sample_chunks

    @property
    def requires_llm(self) -> bool:
        """Ð¢Ñ€ÐµÐ±ÑƒÐµÑ‚ÑÑ LLM"""
        return True

    @property
    def requires_embeddings(self) -> bool:
        """Embeddings Ð½Ðµ Ð¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹"""
        return False

    async def analyze(
        self,
        text: BaseText,
        mode: AnalysisMode,
        **kwargs
    ) -> AnalysisResult:
        """
        Ð’Ñ‹Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÑŒ Ð°Ð½Ð°Ð»Ð¸Ð· Ñ‚ÐµÐ¼

        Args:
            text: Ð¢ÐµÐºÑÑ‚ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°
            mode: Ð ÐµÐ¶Ð¸Ð¼ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°
            **kwargs: Ð”Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹

        Returns:
            AnalysisResult: Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°
        """
        try:
            logger.info(f"ÐÐ°Ñ‡Ð°Ð»Ð¾ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ñ‚ÐµÐ¼: {text.title}")

            # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ñ‡Ð°Ð½ÐºÐ¸
            chunks = kwargs.get('chunks', [])
            if not chunks:
                raise AnalysisError(
                    "ÐÐ½Ð°Ð»Ð¸Ð· Ñ‚ÐµÐ¼ Ñ‚Ñ€ÐµÐ±ÑƒÐµÑ‚ Ñ‡Ð°Ð½ÐºÐ¸ Ñ‚ÐµÐºÑÑ‚Ð°",
                    details={"text_id": text.id}
                )

            # Ð¡ÐµÐ¼Ð¿Ð»Ð¸Ñ€ÑƒÐµÐ¼ Ñ‡Ð°Ð½ÐºÐ¸ (ÐºÐ°Ð¶Ð´Ñ‹Ð¹ N-Ð¹)
            step = max(len(chunks) // self.sample_chunks, 1)
            sample_chunks = chunks[::step][:self.sample_chunks]

            logger.info(f"ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ {len(sample_chunks)} Ñ‡Ð°Ð½ÐºÐ¾Ð² Ð´Ð»Ñ Ñ‚ÐµÐ¼")

            # Ð¡Ð¾Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ñ‚ÐµÐ¼Ñ‹ Ð¸Ð· ÑÐµÐ¼Ð¿Ð»Ð¾Ð²
            detected_themes = []

            for chunk in sample_chunks:
                try:
                    # Ð¤Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐµÐ¼ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚
                    prompt = self._format_theme_prompt(chunk.content)

                    # LLM Ð·Ð°Ð¿Ñ€Ð¾Ñ
                    result = await self.llm_service.generate(
                        prompt=prompt,
                        max_tokens=256,
                        temperature=0.5
                    )

                    # ÐŸÐ°Ñ€ÑÐ¸Ð¼ Ð¾Ñ‚Ð²ÐµÑ‚
                    theme_data = self._parse_theme_response(result)

                    if theme_data and theme_data.get('theme'):
                        theme_data['position'] = chunk.metadata.get('position_ratio', 0.0)
                        theme_data['chunk_index'] = chunk.index
                        detected_themes.append(theme_data)

                except Exception as e:
                    logger.warning(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ñ‚ÐµÐ¼Ñ‹ Ð² Ñ‡Ð°Ð½ÐºÐµ {chunk.index}: {e}")
                    continue

            # ÐÐ³Ñ€ÐµÐ³Ð¸Ñ€ÑƒÐµÐ¼ Ñ‚ÐµÐ¼Ñ‹
            themes = self._aggregate_themes(detected_themes)

            logger.info(f"ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ {len(themes)} Ð¾ÑÐ½Ð¾Ð²Ð½Ñ‹Ñ… Ñ‚ÐµÐ¼")

            return AnalysisResult(
                analyzer_type=self.__class__.__name__,
                text_id=text.id,
                mode=mode,
                data={
                    "themes": themes,
                    "total_themes": len(themes),
                    "chunks_analyzed": len(sample_chunks),
                    "theme_mentions": len(detected_themes)
                }
            )

        except Exception as e:
            logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ñ‚ÐµÐ¼: {e}")
            raise AnalysisError(
                f"ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ñ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ñ‚ÐµÐ¼Ñ‹: {str(e)}",
                details={"text_id": text.id}
            )

    def _format_theme_prompt(self, chunk_text: str) -> str:
        """
        Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ñ‚ÐµÐ¼

        Args:
            chunk_text: Ð¢ÐµÐºÑÑ‚ Ñ‡Ð°Ð½ÐºÐ°

        Returns:
            str: ÐžÑ‚Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚
        """
        prompt = f"""ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐ¹ Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚ Ñ‚ÐµÐºÑÑ‚Ð° Ð¸ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»Ð¸ Ð¾ÑÐ½Ð¾Ð²Ð½ÑƒÑŽ Ñ‚ÐµÐ¼Ñƒ.

Ð¤Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚:
{chunk_text[:1200]}

Ð—Ð°Ð´Ð°Ñ‡Ð°:
1. ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»Ð¸ ÐžÐ”ÐÐ£ Ð¾ÑÐ½Ð¾Ð²Ð½ÑƒÑŽ Ñ‚ÐµÐ¼Ñƒ Ð¸Ð· ÑÐ¿Ð¸ÑÐºÐ°: Ð»ÑŽÐ±Ð¾Ð²ÑŒ, Ð´Ñ€ÑƒÐ¶Ð±Ð°, Ð¿Ñ€ÐµÐ´Ð°Ñ‚ÐµÐ»ÑŒÑÑ‚Ð²Ð¾, Ð²Ð»Ð°ÑÑ‚ÑŒ, ÑÐ²Ð¾Ð±Ð¾Ð´Ð°, ÑÐµÐ¼ÑŒÑ, Ð¾Ð´Ð¸Ð½Ð¾Ñ‡ÐµÑÑ‚Ð²Ð¾, ÑÐ¿Ñ€Ð°Ð²ÐµÐ´Ð»Ð¸Ð²Ð¾ÑÑ‚ÑŒ, Ð²Ð¾Ð¹Ð½Ð°, ÑÐ¼ÐµÑ€Ñ‚ÑŒ, Ð½Ð°Ð´ÐµÐ¶Ð´Ð°, ÑÑ‚Ñ€Ð°Ñ…, Ð²Ñ‹Ð±Ð¾Ñ€, Ð¶ÐµÑ€Ñ‚Ð²Ð°, Ð´Ñ€ÑƒÐ³Ð¾Ðµ
2. Ð”Ð°Ð¹ ÐºÑ€Ð°Ñ‚ÐºÐ¾Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ (1-2 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ), ÐºÐ°Ðº ÑÑ‚Ð° Ñ‚ÐµÐ¼Ð° Ñ€Ð°ÑÐºÑ€Ñ‹Ð²Ð°ÐµÑ‚ÑÑ Ð² Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚Ðµ
3. ÐŸÑ€Ð¸Ð²ÐµÐ´Ð¸ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÑƒÑŽ Ñ†Ð¸Ñ‚Ð°Ñ‚Ñƒ-Ð¿Ñ€Ð¸Ð¼ÐµÑ€ (Ð´Ð¾ 100 ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð²)

ÐžÑ‚Ð²ÐµÑ‚ÑŒ Ð¡Ð¢Ð ÐžÐ“Ðž Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ JSON:
{{
    "theme": "Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ Ñ‚ÐµÐ¼Ñ‹",
    "description": "ÐºÑ€Ð°Ñ‚ÐºÐ¾Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ",
    "example": "Ñ†Ð¸Ñ‚Ð°Ñ‚Ð° Ð¸Ð· Ñ‚ÐµÐºÑÑ‚Ð°"
}}

JSON:"""

        return prompt

    def _parse_theme_response(self, llm_response: str) -> Dict[str, Any]:
        """
        Ð Ð°ÑÐ¿Ð°Ñ€ÑÐ¸Ñ‚ÑŒ Ð¾Ñ‚Ð²ÐµÑ‚ LLM

        Args:
            llm_response: ÐžÑ‚Ð²ÐµÑ‚ LLM

        Returns:
            Dict: Ð”Ð°Ð½Ð½Ñ‹Ðµ Ñ‚ÐµÐ¼Ñ‹
        """
        try:
            # Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ JSON
            json_match = re.search(r'\{[^{}]*\}', llm_response, re.DOTALL)

            if json_match:
                parsed = json.loads(json_match.group(0))
                return parsed

            return {}

        except Exception as e:
            logger.warning(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ð° Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ñ‚ÐµÐ¼Ñ‹: {e}")
            return {}

    def _aggregate_themes(self, theme_mentions: List[Dict]) -> List[Dict]:
        """
        ÐÐ³Ñ€ÐµÐ³Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ ÑƒÐ¿Ð¾Ð¼Ð¸Ð½Ð°Ð½Ð¸Ñ Ñ‚ÐµÐ¼

        ÐžÐ±ÑŠÐµÐ´Ð¸Ð½ÑÐµÑ‚ Ð¾Ð´Ð¸Ð½Ð°ÐºÐ¾Ð²Ñ‹Ðµ Ñ‚ÐµÐ¼Ñ‹, ÑÑ‡Ð¸Ñ‚Ð°ÐµÑ‚ Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ñƒ

        Args:
            theme_mentions: Ð¡Ð¿Ð¸ÑÐ¾Ðº ÑƒÐ¿Ð¾Ð¼Ð¸Ð½Ð°Ð½Ð¸Ð¹ Ñ‚ÐµÐ¼

        Returns:
            List[Dict]: Ð¡Ð¿Ð¸ÑÐ¾Ðº Ð°Ð³Ñ€ÐµÐ³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… Ñ‚ÐµÐ¼
        """
        theme_map = {}

        for mention in theme_mentions:
            theme_name = mention.get('theme', '').strip().lower()
            if not theme_name or theme_name == "Ð´Ñ€ÑƒÐ³Ð¾Ðµ":
                continue

            if theme_name not in theme_map:
                theme_map[theme_name] = {
                    "theme": theme_name.capitalize(),
                    "descriptions": [],
                    "examples": [],
                    "positions": [],
                    "frequency": 0
                }

            theme = theme_map[theme_name]
            theme['frequency'] += 1

            # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ
            desc = mention.get('description', '')
            if desc and desc not in theme['descriptions']:
                theme['descriptions'].append(desc)

            # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¿Ñ€Ð¸Ð¼ÐµÑ€
            example = mention.get('example', '')
            if example and example not in theme['examples']:
                theme['examples'].append(example)

            # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¿Ð¾Ð·Ð¸Ñ†Ð¸ÑŽ
            position = mention.get('position', 0.0)
            theme['positions'].append(position)

        # ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð² ÑÐ¿Ð¸ÑÐ¾Ðº Ð¸ ÑÐ¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð¿Ð¾ Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ðµ
        themes = []
        for theme in theme_map.values():
            # Ð‘ÐµÑ€Ñ‘Ð¼ 2-3 Ð»ÑƒÑ‡ÑˆÐ¸Ñ… Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ñ
            theme['descriptions'] = theme['descriptions'][:3]

            # Ð‘ÐµÑ€Ñ‘Ð¼ 2-3 Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ð°
            theme['examples'] = theme['examples'][:3]

            # Ð¡Ñ€ÐµÐ´Ð½ÑÑ Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ñ
            if theme['positions']:
                theme['avg_position'] = sum(theme['positions']) / len(theme['positions'])
            else:
                theme['avg_position'] = 0.0

            # Ð£Ð±Ð¸Ñ€Ð°ÐµÐ¼ positions (Ð½Ðµ Ð½ÑƒÐ¶Ð½Ñ‹ Ð² Ñ„Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ð¼ Ð²Ñ‹Ð²Ð¾Ð´Ðµ)
            del theme['positions']

            themes.append(theme)

        # Ð¡Ð¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð¿Ð¾ Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ðµ
        themes.sort(key=lambda x: x['frequency'], reverse=True)

        # ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡Ð¸Ð²Ð°ÐµÐ¼ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾
        return themes[:self.max_themes]

    def interpret_results(self, result: AnalysisResult) -> str:
        """
        Ð˜Ð½Ñ‚ÐµÑ€Ð¿Ñ€ÐµÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°

        Args:
            result: Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°

        Returns:
            str: Ð§ÐµÐ»Ð¾Ð²ÐµÐºÐ¾Ñ‡Ð¸Ñ‚Ð°ÐµÐ¼Ð°Ñ Ð¸Ð½Ñ‚ÐµÑ€Ð¿Ñ€ÐµÑ‚Ð°Ñ†Ð¸Ñ
        """
        data = result.data
        themes = data.get('themes', [])
        total = data.get('total_themes', 0)

        if not themes:
            return "ðŸ“– Ð¢ÐµÐ¼Ñ‹ Ð½Ðµ Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ñ‹ Ð² Ñ‚ÐµÐºÑÑ‚Ðµ."

        lines = [
            f"ðŸ“– **ÐÐ½Ð°Ð»Ð¸Ð· Ñ‚ÐµÐ¼ Ð¿Ñ€Ð¾Ð¸Ð·Ð²ÐµÐ´ÐµÐ½Ð¸Ñ**\n",
            f"ðŸ” ÐžÐ±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð¾ Ð¾ÑÐ½Ð¾Ð²Ð½Ñ‹Ñ… Ñ‚ÐµÐ¼: {total}\n"
        ]

        for i, theme in enumerate(themes, 1):
            theme_name = theme.get('theme', 'ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð°Ñ')
            frequency = theme.get('frequency', 0)
            descriptions = theme.get('descriptions', [])
            examples = theme.get('examples', [])

            lines.append(f"**{i}. {theme_name}** (Ð²ÑÑ‚Ñ€ÐµÑ‡Ð°ÐµÑ‚ÑÑ {frequency} Ñ€Ð°Ð·)")

            if descriptions:
                lines.append(f"   ðŸ’¬ {descriptions[0]}")

            if examples:
                lines.append(f"   ðŸ“ ÐŸÑ€Ð¸Ð¼ÐµÑ€: \"{examples[0][:100]}...\"")

            lines.append("")

        # Ð’Ñ‹Ð²Ð¾Ð´
        main_themes = [t.get('theme', '') for t in themes[:3]]
        lines.append(
            f"ðŸ’¡ **Ð’Ñ‹Ð²Ð¾Ð´**: ÐŸÑ€Ð¾Ð¸Ð·Ð²ÐµÐ´ÐµÐ½Ð¸Ðµ Ð¸ÑÑÐ»ÐµÐ´ÑƒÐµÑ‚ Ñ‚ÐµÐ¼Ñ‹: "
            f"{', '.join(main_themes).lower()}."
        )

        return '\n'.join(lines)

    def _create_default_prompt(self) -> PromptTemplate:
        """Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ð´ÐµÑ„Ð¾Ð»Ñ‚Ð½Ñ‹Ð¹ ÑˆÐ°Ð±Ð»Ð¾Ð½ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ð°"""
        return PromptTemplate.create_default_theme_prompt()
