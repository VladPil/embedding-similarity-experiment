"""
ÐÐ½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€ Ñ‚ÐµÐ¼ Ð¿Ñ€Ð¾Ð¸Ð·Ð²ÐµÐ´ÐµÐ½Ð¸Ñ
"""
import json
import re
from typing import Dict, Any, List, Optional
from loguru import logger

from ..entities.base_analyzer import BaseAnalyzer
from ..entities.analysis_result import AnalysisResult
from ..entities.prompt_template import PromptTemplate
from src.text_domain.entities.base_text import BaseText
from src.common.types import AnalysisMode
from src.common.exceptions import AnalysisError


class ThemeAnalyzer(BaseAnalyzer):
    """
    ÐÐ½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€ Ð¾ÑÐ½Ð¾Ð²Ð½Ñ‹Ñ… Ñ‚ÐµÐ¼ Ð¿Ñ€Ð¾Ð¸Ð·Ð²ÐµÐ´ÐµÐ½Ð¸Ñ

    Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚:
    - Ð¡ÐµÐ¼Ð¿Ð»Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ‡Ð°Ð½ÐºÐ¾Ð² (ÐºÐ°Ð¶Ð´Ñ‹Ð¹ 10-Ð¹)
    - LLM Ð´Ð»Ñ Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ñ Ñ‚ÐµÐ¼
    - ÐÐ³Ñ€ÐµÐ³Ð°Ñ†Ð¸ÑŽ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€ÑÑŽÑ‰Ð¸Ñ…ÑÑ Ñ‚ÐµÐ¼

    Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚:
    - Ð¡Ð¿Ð¸ÑÐ¾Ðº Ð¾ÑÐ½Ð¾Ð²Ð½Ñ‹Ñ… Ñ‚ÐµÐ¼
    - ÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ ÐºÐ°Ð¶Ð´Ð¾Ð¹ Ñ‚ÐµÐ¼Ñ‹
    - ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹ Ð¸Ð· Ñ‚ÐµÐºÑÑ‚Ð°
    - Ð§Ð°ÑÑ‚Ð¾Ñ‚Ñƒ Ð²ÑÑ‚Ñ€ÐµÑ‡Ð°ÐµÐ¼Ð¾ÑÑ‚Ð¸
    """

    def __init__(
        self,
        llm_service: Optional[Any] = None,
        prompt_template: Optional[PromptTemplate] = None,
        max_themes: int = 5,
        sample_chunks: int = 10
    ):
        """
        Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð° Ñ‚ÐµÐ¼

        Args:
            llm_service: Ð¡ÐµÑ€Ð²Ð¸Ñ Ð´Ð»Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ñ LLM
            prompt_template: Ð¨Ð°Ð±Ð»Ð¾Ð½ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ð°
            max_themes: ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ðµ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ñ‚ÐµÐ¼
            sample_chunks: ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ñ‡Ð°Ð½ÐºÐ¾Ð² Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°
        """
        self.llm_service = llm_service
        self.prompt_template = prompt_template or self._create_default_prompt()
        self.max_themes = max_themes
        self.sample_chunks = sample_chunks

    @property
    def name(self) -> str:
        """Ð£Ð½Ð¸ÐºÐ°Ð»ÑŒÐ½Ð¾Ðµ Ð¸Ð¼Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð°"""
        return "theme"

    @property
    def display_name(self) -> str:
        """Ð§ÐµÐ»Ð¾Ð²ÐµÐºÐ¾Ñ‡Ð¸Ñ‚Ð°ÐµÐ¼Ð¾Ðµ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ"""
        return "ÐÐ½Ð°Ð»Ð¸Ð· Ñ‚ÐµÐ¼"

    @property
    def description(self) -> str:
        """ÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð°"""
        return "ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÑ‚ Ð¾ÑÐ½Ð¾Ð²Ð½Ñ‹Ðµ Ñ‚ÐµÐ¼Ñ‹ Ð¸ Ð¼Ð¾Ñ‚Ð¸Ð²Ñ‹ Ð¿Ñ€Ð¾Ð¸Ð·Ð²ÐµÐ´ÐµÐ½Ð¸Ñ Ñ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼ LLM"

    @property
    def requires_llm(self) -> bool:
        """Ð¢Ñ€ÐµÐ±ÑƒÐµÑ‚ÑÑ LLM"""
        return True

    @property
    def requires_embeddings(self) -> bool:
        """Embeddings Ð½Ðµ Ð¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹"""
        return False

    async def analyze(
        self,
        text: BaseText,
        mode: AnalysisMode,
        **kwargs
    ) -> AnalysisResult:
        """
        Ð’Ñ‹Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÑŒ Ð°Ð½Ð°Ð»Ð¸Ð· Ñ‚ÐµÐ¼

        Args:
            text: Ð¢ÐµÐºÑÑ‚ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°
            mode: Ð ÐµÐ¶Ð¸Ð¼ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°
            **kwargs: Ð”Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹

        Returns:
            AnalysisResult: Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°
        """
        try:
            logger.info(f"ÐÐ°Ñ‡Ð°Ð»Ð¾ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ñ‚ÐµÐ¼: {text.title}")

            # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ñ‡Ð°Ð½ÐºÐ¸
            chunks = kwargs.get('chunks', [])
            if not chunks:
                raise AnalysisError(
                    "ÐÐ½Ð°Ð»Ð¸Ð· Ñ‚ÐµÐ¼ Ñ‚Ñ€ÐµÐ±ÑƒÐµÑ‚ Ñ‡Ð°Ð½ÐºÐ¸ Ñ‚ÐµÐºÑÑ‚Ð°",
                    details={"text_id": text.id}
                )

            # Ð¡ÐµÐ¼Ð¿Ð»Ð¸Ñ€ÑƒÐµÐ¼ Ñ‡Ð°Ð½ÐºÐ¸ (ÐºÐ°Ð¶Ð´Ñ‹Ð¹ N-Ð¹)
            step = max(len(chunks) // self.sample_chunks, 1)
            sample_chunks = chunks[::step][:self.sample_chunks]

            logger.info(f"ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ {len(sample_chunks)} Ñ‡Ð°Ð½ÐºÐ¾Ð² Ð´Ð»Ñ Ñ‚ÐµÐ¼")

            # Ð¡Ð¾Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ñ‚ÐµÐ¼Ñ‹ Ð¸Ð· ÑÐµÐ¼Ð¿Ð»Ð¾Ð²
            detected_themes = []

            for chunk in sample_chunks:
                try:
                    # Ð¤Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐµÐ¼ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚
                    prompt = self._format_theme_prompt(chunk.content)

                    # LLM Ð·Ð°Ð¿Ñ€Ð¾Ñ
                    result = await self.llm_service.generate(
                        prompt=prompt,
                        max_tokens=256,
                        temperature=0.5
                    )

                    # ÐŸÐ°Ñ€ÑÐ¸Ð¼ Ð¾Ñ‚Ð²ÐµÑ‚
                    theme_data = self._parse_theme_response(result)

                    if theme_data and theme_data.get('theme'):
                        theme_data['position'] = chunk.metadata.get('position_ratio', 0.0)
                        theme_data['chunk_index'] = chunk.index
                        detected_themes.append(theme_data)

                except Exception as e:
                    logger.warning(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ñ‚ÐµÐ¼Ñ‹ Ð² Ñ‡Ð°Ð½ÐºÐµ {chunk.index}: {e}")
                    continue

            # ÐÐ³Ñ€ÐµÐ³Ð¸Ñ€ÑƒÐµÐ¼ Ñ‚ÐµÐ¼Ñ‹
            themes = self._aggregate_themes(detected_themes)

            logger.info(f"ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ {len(themes)} Ð¾ÑÐ½Ð¾Ð²Ð½Ñ‹Ñ… Ñ‚ÐµÐ¼")

            return AnalysisResult(
                text_id=text.id,
                analyzer_name=self.name,
                mode=mode,
                data={
                    "themes": themes,
                    "total_themes": len(themes),
                    "chunks_analyzed": len(sample_chunks),
                    "theme_mentions": len(detected_themes)
                }
            )

        except Exception as e:
            logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ñ‚ÐµÐ¼: {e}")
            raise AnalysisError(
                f"ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ñ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ñ‚ÐµÐ¼Ñ‹: {str(e)}",
                details={"text_id": text.id}
            )

    def _format_theme_prompt(self, chunk_text: str) -> str:
        """
        Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ñ‚ÐµÐ¼

        Args:
            chunk_text: Ð¢ÐµÐºÑÑ‚ Ñ‡Ð°Ð½ÐºÐ°

        Returns:
            str: ÐžÑ‚Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚
        """

        # ÐžÐ±Ð¾Ð³Ð°Ñ‰ÐµÐ½Ð½Ñ‹Ð¹ ÑÐ¿Ð¸ÑÐ¾Ðº Ñ‚ÐµÐ¼ Ñ Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ð°Ð¼Ð¸
        themes_examples = {
            "Ð»ÑŽÐ±Ð¾Ð²ÑŒ": ["Ñ€Ð¾Ð¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð»ÑŽÐ±Ð¾Ð²ÑŒ", "Ð¼Ð°Ñ‚ÐµÑ€Ð¸Ð½ÑÐºÐ°Ñ Ð»ÑŽÐ±Ð¾Ð²ÑŒ", "Ð±ÐµÐ·Ð¾Ñ‚Ð²ÐµÑ‚Ð½Ð°Ñ Ð»ÑŽÐ±Ð¾Ð²ÑŒ", "Ð¿ÐµÑ€Ð²Ð°Ñ Ð»ÑŽÐ±Ð¾Ð²ÑŒ", "Ð·Ð°Ð¿Ñ€ÐµÑ‚Ð½Ð°Ñ Ð»ÑŽÐ±Ð¾Ð²ÑŒ"],
            "Ð´Ñ€ÑƒÐ¶Ð±Ð°": ["Ð²ÐµÑ€Ð½Ð¾ÑÑ‚ÑŒ Ð´Ñ€ÑƒÐ·ÑŒÑÐ¼", "Ð½Ð°ÑÑ‚Ð¾ÑÑ‰Ð°Ñ Ð´Ñ€ÑƒÐ¶Ð±Ð°", "Ð¸ÑÐ¿Ñ‹Ñ‚Ð°Ð½Ð¸Ðµ Ð´Ñ€ÑƒÐ¶Ð±Ð¾Ð¹", "Ð´ÐµÑ‚ÑÐºÐ°Ñ Ð´Ñ€ÑƒÐ¶Ð±Ð°", "Ð¼ÑƒÐ¶ÑÐºÐ°Ñ Ð´Ñ€ÑƒÐ¶Ð±Ð°"],
            "Ð¿Ñ€ÐµÐ´Ð°Ñ‚ÐµÐ»ÑŒÑÑ‚Ð²Ð¾": ["Ð¸Ð·Ð¼ÐµÐ½Ð°", "Ð¾Ð±Ð¼Ð°Ð½", "Ð½Ð°Ñ€ÑƒÑˆÐµÐ½Ð¸Ðµ Ð´Ð¾Ð²ÐµÑ€Ð¸Ñ", "Ð¿Ñ€ÐµÐ´Ð°Ñ‚ÐµÐ»ÑŒÑÑ‚Ð²Ð¾ Ð±Ð»Ð¸Ð·ÐºÐ¸Ñ…", "Ð¿Ð¾Ð»Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ð¿Ñ€ÐµÐ´Ð°Ñ‚ÐµÐ»ÑŒÑÑ‚Ð²Ð¾"],
            "Ð²Ð»Ð°ÑÑ‚ÑŒ": ["Ð±Ð¾Ñ€ÑŒÐ±Ð° Ð·Ð° Ð²Ð»Ð°ÑÑ‚ÑŒ", "Ð·Ð»Ð¾ÑƒÐ¿Ð¾Ñ‚Ñ€ÐµÐ±Ð»ÐµÐ½Ð¸Ðµ Ð²Ð»Ð°ÑÑ‚ÑŒÑŽ", "ÐºÐ¾Ñ€Ñ€ÑƒÐ¿Ñ†Ð¸Ñ", "Ñ‚Ð¸Ñ€Ð°Ð½Ð¸Ñ", "Ð¿Ð¾Ð»Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð¸Ð½Ñ‚Ñ€Ð¸Ð³Ð¸"],
            "ÑÐ²Ð¾Ð±Ð¾Ð´Ð°": ["Ð±Ð¾Ñ€ÑŒÐ±Ð° Ð·Ð° Ð½ÐµÐ·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚ÑŒ", "Ð»Ð¸Ñ‡Ð½Ð°Ñ ÑÐ²Ð¾Ð±Ð¾Ð´Ð°", "Ð¾ÑÐ²Ð¾Ð±Ð¾Ð¶Ð´ÐµÐ½Ð¸Ðµ", "ÑÐ²Ð¾Ð±Ð¾Ð´Ð° Ð²Ñ‹Ð±Ð¾Ñ€Ð°", "ÑÐ²Ð¾Ð±Ð¾Ð´Ð° ÑÐ»Ð¾Ð²Ð°"],
            "ÑÐµÐ¼ÑŒÑ": ["ÑÐµÐ¼ÐµÐ¹Ð½Ñ‹Ðµ Ñ†ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸", "Ñ€Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÑÐºÐ°Ñ Ð»ÑŽÐ±Ð¾Ð²ÑŒ", "ÑÐµÐ¼ÐµÐ¹Ð½Ñ‹Ðµ ÐºÐ¾Ð½Ñ„Ð»Ð¸ÐºÑ‚Ñ‹", "Ð¿Ð¾ÐºÐ¾Ð»ÐµÐ½Ð¸Ñ", "Ð½Ð°ÑÐ»ÐµÐ´ÑÑ‚Ð²Ð¾"],
            "Ð¾Ð´Ð¸Ð½Ð¾Ñ‡ÐµÑÑ‚Ð²Ð¾": ["Ð¸Ð·Ð¾Ð»ÑÑ†Ð¸Ñ", "Ð¾Ñ‚Ñ‡ÑƒÐ¶Ð´ÐµÐ½Ð¸Ðµ", "ÑÐ¾Ñ†Ð¸Ð°Ð»ÑŒÐ½Ð¾Ðµ Ð¾Ð´Ð¸Ð½Ð¾Ñ‡ÐµÑÑ‚Ð²Ð¾", "Ð²Ð½ÑƒÑ‚Ñ€ÐµÐ½Ð½ÐµÐµ Ð¾Ð´Ð¸Ð½Ð¾Ñ‡ÐµÑÑ‚Ð²Ð¾", "Ð¿Ð¾ÐºÐ¸Ð½ÑƒÑ‚Ð¾ÑÑ‚ÑŒ"],
            "ÑÐ¿Ñ€Ð°Ð²ÐµÐ´Ð»Ð¸Ð²Ð¾ÑÑ‚ÑŒ": ["Ð±Ð¾Ñ€ÑŒÐ±Ð° Ð·Ð° ÑÐ¿Ñ€Ð°Ð²ÐµÐ´Ð»Ð¸Ð²Ð¾ÑÑ‚ÑŒ", "Ð¿Ñ€Ð°Ð²Ð¾ÑÑƒÐ´Ð¸Ðµ", "Ð¼ÐµÑÑ‚ÑŒ", "Ð½Ð°ÐºÐ°Ð·Ð°Ð½Ð¸Ðµ", "Ð²Ð¾ÑÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ ÑÐ¿Ñ€Ð°Ð²ÐµÐ´Ð»Ð¸Ð²Ð¾ÑÑ‚Ð¸"],
            "Ð²Ð¾Ð¹Ð½Ð°": ["Ð²Ð¾ÐµÐ½Ð½Ñ‹Ðµ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ", "Ð³ÐµÑ€Ð¾Ð¸Ð·Ð¼ Ð½Ð° Ð²Ð¾Ð¹Ð½Ðµ", "Ð¿Ð¾Ñ‚ÐµÑ€Ð¸ Ð²Ð¾Ð¹Ð½Ñ‹", "Ð±Ñ€Ð°Ñ‚ÑÑ‚Ð²Ð¾ Ð½Ð° Ð²Ð¾Ð¹Ð½Ðµ", "Ð°Ð½Ñ‚Ð¸Ð²Ð¾ÐµÐ½Ð½Ð°Ñ Ñ‚ÐµÐ¼Ð°"],
            "ÑÐ¼ÐµÑ€Ñ‚ÑŒ": ["ÑÐºÐ¾Ñ€Ð±ÑŒ", "Ð±ÐµÑÑÐ¼ÐµÑ€Ñ‚Ð¸Ðµ", "ÑÐ¼Ñ‹ÑÐ» Ð¶Ð¸Ð·Ð½Ð¸ Ð¿ÐµÑ€ÐµÐ´ Ð»Ð¸Ñ†Ð¾Ð¼ ÑÐ¼ÐµÑ€Ñ‚Ð¸", "Ð¿Ð°Ð¼ÑÑ‚ÑŒ Ð¾ ÑƒÐ¼ÐµÑ€ÑˆÐ¸Ñ…", "ÑÑ‚Ñ€Ð°Ñ… ÑÐ¼ÐµÑ€Ñ‚Ð¸"],
            "Ð½Ð°Ð´ÐµÐ¶Ð´Ð°": ["Ð²ÐµÑ€Ð° Ð² Ð»ÑƒÑ‡ÑˆÐµÐµ", "Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¼", "Ð¼ÐµÑ‡Ñ‚Ñ‹", "ÑÑ‚Ñ€ÐµÐ¼Ð»ÐµÐ½Ð¸Ðµ Ðº Ñ†ÐµÐ»Ð¸", "Ð¿Ñ€ÐµÐ¾Ð´Ð¾Ð»ÐµÐ½Ð¸Ðµ Ñ‚Ñ€ÑƒÐ´Ð½Ð¾ÑÑ‚ÐµÐ¹"],
            "ÑÑ‚Ñ€Ð°Ñ…": ["Ñ„Ð¾Ð±Ð¸Ð¸", "Ñ‚Ñ€ÐµÐ²Ð¾Ð³Ð°", "ÑƒÐ¶Ð°Ñ", "Ð±Ð¾ÑÐ·Ð½ÑŒ Ð½ÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð¾Ð³Ð¾", "Ð¿Ð°Ñ€Ð°Ð½Ð¾Ð¹Ñ"],
            "Ð²Ñ‹Ð±Ð¾Ñ€": ["Ð¼Ð¾Ñ€Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð²Ñ‹Ð±Ð¾Ñ€", "Ð¶Ð¸Ð·Ð½ÐµÐ½Ð½Ñ‹Ðµ Ñ€ÐµÑˆÐµÐ½Ð¸Ñ", "Ð´Ð¸Ð»ÐµÐ¼Ð¼Ð°", "Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ Ð·Ð° Ð²Ñ‹Ð±Ð¾Ñ€", "Ð¿Ð¾ÑÐ»ÐµÐ´ÑÑ‚Ð²Ð¸Ñ Ñ€ÐµÑˆÐµÐ½Ð¸Ð¹"],
            "Ð¶ÐµÑ€Ñ‚Ð²Ð°": ["ÑÐ°Ð¼Ð¾Ð¿Ð¾Ð¶ÐµÑ€Ñ‚Ð²Ð¾Ð²Ð°Ð½Ð¸Ðµ", "Ð¶ÐµÑ€Ñ‚Ð²Ð° Ñ€Ð°Ð´Ð¸ Ð´Ñ€ÑƒÐ³Ð¸Ñ…", "Ð¶ÐµÑ€Ñ‚Ð²Ð° Ñ€Ð°Ð´Ð¸ Ð¸Ð´ÐµÐ¸", "Ð¼Ð°Ñ‚ÐµÑ€Ð¸Ð½ÑÐºÐ°Ñ Ð¶ÐµÑ€Ñ‚Ð²Ð°", "Ð³ÐµÑ€Ð¾Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð¶ÐµÑ€Ñ‚Ð²Ð°"],
            "Ð²ÐµÑ€Ð°": ["Ñ€ÐµÐ»Ð¸Ð³Ð¸Ð¾Ð·Ð½Ð°Ñ Ð²ÐµÑ€Ð°", "Ð²ÐµÑ€Ð° Ð² ÑÐµÐ±Ñ", "Ð´ÑƒÑ…Ð¾Ð²Ð½Ð¾ÑÑ‚ÑŒ", "Ð¿Ð¾Ñ‚ÐµÑ€Ñ Ð²ÐµÑ€Ñ‹", "Ð¿Ð¾Ð¸ÑÐº ÑÐ¼Ñ‹ÑÐ»Ð°"],
            "Ñ‡ÐµÑÑ‚ÑŒ": ["Ð»Ð¸Ñ‡Ð½Ð°Ñ Ñ‡ÐµÑÑ‚ÑŒ", "Ñ‡ÐµÑÑ‚ÑŒ ÑÐµÐ¼ÑŒÐ¸", "Ñ€Ñ‹Ñ†Ð°Ñ€ÑÐºÐ°Ñ Ñ‡ÐµÑÑ‚ÑŒ", "Ð¿Ñ€Ð¾Ñ„ÐµÑÑÐ¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð°Ñ Ñ‡ÐµÑÑ‚ÑŒ", "Ð·Ð°Ñ‰Ð¸Ñ‚Ð° Ñ‡ÐµÑÑ‚Ð¸"],
            "Ð´Ð¾Ð»Ð³": ["Ð²Ð¾Ð¸Ð½ÑÐºÐ¸Ð¹ Ð´Ð¾Ð»Ð³", "ÑÐµÐ¼ÐµÐ¹Ð½Ñ‹Ð¹ Ð´Ð¾Ð»Ð³", "Ð³Ñ€Ð°Ð¶Ð´Ð°Ð½ÑÐºÐ¸Ð¹ Ð´Ð¾Ð»Ð³", "Ð¼Ð¾Ñ€Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÑÑ‚Ð²Ð°", "ÑÐ»ÑƒÐ¶ÐµÐ½Ð¸Ðµ"],
            "Ð¸ÑÐºÑƒÐ¿Ð»ÐµÐ½Ð¸Ðµ": ["Ñ€Ð°ÑÐºÐ°ÑÐ½Ð¸Ðµ", "Ð¿Ñ€Ð¾Ñ‰ÐµÐ½Ð¸Ðµ", "Ð¸ÑÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð¾ÑˆÐ¸Ð±Ð¾Ðº", "Ð¼Ð¾Ñ€Ð°Ð»ÑŒÐ½Ð¾Ðµ Ð¾Ñ‡Ð¸Ñ‰ÐµÐ½Ð¸Ðµ", "Ð²Ñ‚Ð¾Ñ€Ð¾Ð¹ ÑˆÐ°Ð½Ñ"],
            "Ð¼ÐµÑÑ‚ÑŒ": ["ÐºÑ€Ð¾Ð²Ð½Ð°Ñ Ð¼ÐµÑÑ‚ÑŒ", "ÑÐ¿Ñ€Ð°Ð²ÐµÐ´Ð»Ð¸Ð²Ð¾Ðµ Ð²Ð¾Ð·Ð¼ÐµÐ·Ð´Ð¸Ðµ", "Ð»Ð¸Ñ‡Ð½Ð°Ñ Ð¼ÐµÑÑ‚ÑŒ", "Ñ†Ð¸ÐºÐ»Ñ‹ Ð½Ð°ÑÐ¸Ð»Ð¸Ñ", "Ñ†ÐµÐ½Ð° Ð¼ÐµÑÑ‚Ð¸"],
            "Ð¿Ñ€Ð¸Ñ€Ð¾Ð´Ð°": ["ÑÐ²ÑÐ·ÑŒ Ñ Ð¿Ñ€Ð¸Ñ€Ð¾Ð´Ð¾Ð¹", "ÑÐºÐ¾Ð»Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹", "Ð³Ð°Ñ€Ð¼Ð¾Ð½Ð¸Ñ Ñ Ð¿Ñ€Ð¸Ñ€Ð¾Ð´Ð¾Ð¹", "Ð¿Ñ€Ð¸Ñ€Ð¾Ð´Ð° vs Ñ†Ð¸Ð²Ð¸Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ", "ÑÑ‚Ð¸Ñ…Ð¸Ð¸"],
            "Ð²Ñ€ÐµÐ¼Ñ": ["Ð±Ñ‹ÑÑ‚Ñ€Ð¾Ñ‚ÐµÑ‡Ð½Ð¾ÑÑ‚ÑŒ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸", "Ð¿Ð°Ð¼ÑÑ‚ÑŒ Ð¾ Ð¿Ñ€Ð¾ÑˆÐ»Ð¾Ð¼", "Ð±ÑƒÐ´ÑƒÑ‰ÐµÐµ", "Ñ†Ð¸ÐºÐ»Ñ‹ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸", "Ð²ÐµÑ‡Ð½Ð¾ÑÑ‚ÑŒ"],
            "Ð¿Ð¾Ð·Ð½Ð°Ð½Ð¸Ðµ": ["Ð¿Ð¾Ð¸ÑÐº Ð¸ÑÑ‚Ð¸Ð½Ñ‹", "Ð½Ð°ÑƒÑ‡Ð½Ð¾Ðµ Ð¾Ñ‚ÐºÑ€Ñ‹Ñ‚Ð¸Ðµ", "ÑÐ°Ð¼Ð¾Ð¿Ð¾Ð·Ð½Ð°Ð½Ð¸Ðµ", "Ñ„Ð¸Ð»Ð¾ÑÐ¾Ñ„ÑÐºÐ¸Ðµ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹", "Ð¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ð½Ð¸Ðµ"],
            "Ñ‚Ð²Ð¾Ñ€Ñ‡ÐµÑÑ‚Ð²Ð¾": ["Ð¸ÑÐºÑƒÑÑÑ‚Ð²Ð¾", "Ð²Ð´Ð¾Ñ…Ð½Ð¾Ð²ÐµÐ½Ð¸Ðµ", "Ñ‚Ð²Ð¾Ñ€Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¿Ñ€Ð¾Ñ†ÐµÑÑ", "Ñ‚Ð°Ð»Ð°Ð½Ñ‚", "ÑÐ°Ð¼Ð¾Ð²Ñ‹Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ"],
            "Ð±Ð¾Ð³Ð°Ñ‚ÑÑ‚Ð²Ð¾": ["Ð¼Ð°Ñ‚ÐµÑ€Ð¸Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ñ†ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸", "Ð¶Ð°Ð´Ð½Ð¾ÑÑ‚ÑŒ", "ÑÐ¾Ñ†Ð¸Ð°Ð»ÑŒÐ½Ð¾Ðµ Ð½ÐµÑ€Ð°Ð²ÐµÐ½ÑÑ‚Ð²Ð¾", "Ñ†ÐµÐ½Ð° ÑƒÑÐ¿ÐµÑ…Ð°", "Ð´ÑƒÑ…Ð¾Ð²Ð½Ð¾Ðµ Ð±Ð¾Ð³Ð°Ñ‚ÑÑ‚Ð²Ð¾"],
            "Ð¿ÑƒÑ‚ÐµÑˆÐµÑÑ‚Ð²Ð¸Ðµ": ["Ñ„Ð¸Ð·Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ð¿ÑƒÑ‚ÐµÑˆÐµÑÑ‚Ð²Ð¸Ðµ", "Ð´ÑƒÑ…Ð¾Ð²Ð½Ñ‹Ð¹ Ð¿ÑƒÑ‚ÑŒ", "Ð¿Ð¾Ð¸ÑÐºÐ¸", "Ð¿Ñ€Ð¸ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ", "Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰ÐµÐ½Ð¸Ðµ Ð´Ð¾Ð¼Ð¾Ð¹"]
        }

        all_themes = list(themes_examples.keys())

        prompt = f"""ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐ¹ Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚ Ñ‚ÐµÐºÑÑ‚Ð° Ð¸ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»Ð¸ Ð¾ÑÐ½Ð¾Ð²Ð½ÑƒÑŽ Ñ‚ÐµÐ¼Ñƒ.

Ð¤Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚:
{chunk_text[:1200]}

Ð’Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ñ‹Ðµ Ñ‚ÐµÐ¼Ñ‹ (Ð²Ñ‹Ð±ÐµÑ€Ð¸ ÐžÐ”ÐÐ£ Ð½Ð°Ð¸Ð±Ð¾Ð»ÐµÐµ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ÑÑ‰ÑƒÑŽ):
{', '.join(all_themes)}

ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹ Ð¿Ð¾Ð´Ñ‚ÐµÐ¼:
â€¢ Ð›ÑŽÐ±Ð¾Ð²ÑŒ: {', '.join(themes_examples['Ð»ÑŽÐ±Ð¾Ð²ÑŒ'])}
â€¢ Ð”Ñ€ÑƒÐ¶Ð±Ð°: {', '.join(themes_examples['Ð´Ñ€ÑƒÐ¶Ð±Ð°'])}
â€¢ Ð’Ð»Ð°ÑÑ‚ÑŒ: {', '.join(themes_examples['Ð²Ð»Ð°ÑÑ‚ÑŒ'])}
â€¢ Ð¡Ð²Ð¾Ð±Ð¾Ð´Ð°: {', '.join(themes_examples['ÑÐ²Ð¾Ð±Ð¾Ð´Ð°'])}
â€¢ Ð¡Ð¿Ñ€Ð°Ð²ÐµÐ´Ð»Ð¸Ð²Ð¾ÑÑ‚ÑŒ: {', '.join(themes_examples['ÑÐ¿Ñ€Ð°Ð²ÐµÐ´Ð»Ð¸Ð²Ð¾ÑÑ‚ÑŒ'])}
â€¢ Ð’Ñ‹Ð±Ð¾Ñ€: {', '.join(themes_examples['Ð²Ñ‹Ð±Ð¾Ñ€'])}
â€¢ Ð–ÐµÑ€Ñ‚Ð²Ð°: {', '.join(themes_examples['Ð¶ÐµÑ€Ñ‚Ð²Ð°'])}
... Ð¸ Ð´Ñ€ÑƒÐ³Ð¸Ðµ Ð¸Ð· ÑÐ¿Ð¸ÑÐºÐ° Ð²Ñ‹ÑˆÐµ

Ð—Ð°Ð´Ð°Ñ‡Ð°:
1. ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»Ð¸ ÐžÐ”ÐÐ£ Ð¾ÑÐ½Ð¾Ð²Ð½ÑƒÑŽ Ñ‚ÐµÐ¼Ñƒ Ð¸Ð· ÑÐ¿Ð¸ÑÐºÐ° Ð²Ñ‹ÑˆÐµ
2. Ð”Ð°Ð¹ ÐºÑ€Ð°Ñ‚ÐºÐ¾Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ (1-2 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ), ÐºÐ°Ðº ÑÑ‚Ð° Ñ‚ÐµÐ¼Ð° Ñ€Ð°ÑÐºÑ€Ñ‹Ð²Ð°ÐµÑ‚ÑÑ Ð² Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚Ðµ
3. ÐŸÑ€Ð¸Ð²ÐµÐ´Ð¸ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÑƒÑŽ Ñ†Ð¸Ñ‚Ð°Ñ‚Ñƒ-Ð¿Ñ€Ð¸Ð¼ÐµÑ€ (Ð´Ð¾ 100 ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð²)

ÐžÑ‚Ð²ÐµÑ‚ÑŒ Ð¡Ð¢Ð ÐžÐ“Ðž Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ JSON:
{{
    "theme": "Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ Ñ‚ÐµÐ¼Ñ‹ Ð¸Ð· ÑÐ¿Ð¸ÑÐºÐ°",
    "description": "ÐºÑ€Ð°Ñ‚ÐºÐ¾Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ",
    "example": "Ñ†Ð¸Ñ‚Ð°Ñ‚Ð° Ð¸Ð· Ñ‚ÐµÐºÑÑ‚Ð°"
}}

JSON:"""

        return prompt

    def _parse_theme_response(self, llm_response: str) -> Dict[str, Any]:
        """
        Ð Ð°ÑÐ¿Ð°Ñ€ÑÐ¸Ñ‚ÑŒ Ð¾Ñ‚Ð²ÐµÑ‚ LLM

        Args:
            llm_response: ÐžÑ‚Ð²ÐµÑ‚ LLM

        Returns:
            Dict: Ð”Ð°Ð½Ð½Ñ‹Ðµ Ñ‚ÐµÐ¼Ñ‹
        """
        try:
            # Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ JSON
            json_match = re.search(r'\{[^{}]*\}', llm_response, re.DOTALL)

            if json_match:
                parsed = json.loads(json_match.group(0))
                return parsed

            return {}

        except Exception as e:
            logger.warning(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ð° Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ñ‚ÐµÐ¼Ñ‹: {e}")
            return {}

    def _aggregate_themes(self, theme_mentions: List[Dict]) -> List[Dict]:
        """
        ÐÐ³Ñ€ÐµÐ³Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ ÑƒÐ¿Ð¾Ð¼Ð¸Ð½Ð°Ð½Ð¸Ñ Ñ‚ÐµÐ¼

        ÐžÐ±ÑŠÐµÐ´Ð¸Ð½ÑÐµÑ‚ Ð¾Ð´Ð¸Ð½Ð°ÐºÐ¾Ð²Ñ‹Ðµ Ñ‚ÐµÐ¼Ñ‹, ÑÑ‡Ð¸Ñ‚Ð°ÐµÑ‚ Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ñƒ

        Args:
            theme_mentions: Ð¡Ð¿Ð¸ÑÐ¾Ðº ÑƒÐ¿Ð¾Ð¼Ð¸Ð½Ð°Ð½Ð¸Ð¹ Ñ‚ÐµÐ¼

        Returns:
            List[Dict]: Ð¡Ð¿Ð¸ÑÐ¾Ðº Ð°Ð³Ñ€ÐµÐ³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… Ñ‚ÐµÐ¼
        """
        theme_map = {}

        for mention in theme_mentions:
            theme_name = mention.get('theme', '').strip().lower()
            if not theme_name or theme_name == "Ð´Ñ€ÑƒÐ³Ð¾Ðµ":
                continue

            if theme_name not in theme_map:
                theme_map[theme_name] = {
                    "theme": theme_name.capitalize(),
                    "descriptions": [],
                    "examples": [],
                    "positions": [],
                    "frequency": 0
                }

            theme = theme_map[theme_name]
            theme['frequency'] += 1

            # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ
            desc = mention.get('description', '')
            if desc and desc not in theme['descriptions']:
                theme['descriptions'].append(desc)

            # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¿Ñ€Ð¸Ð¼ÐµÑ€
            example = mention.get('example', '')
            if example and example not in theme['examples']:
                theme['examples'].append(example)

            # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¿Ð¾Ð·Ð¸Ñ†Ð¸ÑŽ
            position = mention.get('position', 0.0)
            theme['positions'].append(position)

        # ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð² ÑÐ¿Ð¸ÑÐ¾Ðº Ð¸ ÑÐ¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð¿Ð¾ Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ðµ
        themes = []
        for theme in theme_map.values():
            # Ð‘ÐµÑ€Ñ‘Ð¼ 2-3 Ð»ÑƒÑ‡ÑˆÐ¸Ñ… Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ñ
            theme['descriptions'] = theme['descriptions'][:3]

            # Ð‘ÐµÑ€Ñ‘Ð¼ 2-3 Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ð°
            theme['examples'] = theme['examples'][:3]

            # Ð¡Ñ€ÐµÐ´Ð½ÑÑ Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ñ
            if theme['positions']:
                theme['avg_position'] = sum(theme['positions']) / len(theme['positions'])
            else:
                theme['avg_position'] = 0.0

            # Ð£Ð±Ð¸Ñ€Ð°ÐµÐ¼ positions (Ð½Ðµ Ð½ÑƒÐ¶Ð½Ñ‹ Ð² Ñ„Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ð¼ Ð²Ñ‹Ð²Ð¾Ð´Ðµ)
            del theme['positions']

            themes.append(theme)

        # Ð¡Ð¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð¿Ð¾ Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ðµ
        themes.sort(key=lambda x: x['frequency'], reverse=True)

        # ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡Ð¸Ð²Ð°ÐµÐ¼ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾
        return themes[:self.max_themes]

    def interpret_results(self, result: AnalysisResult) -> str:
        """
        Ð˜Ð½Ñ‚ÐµÑ€Ð¿Ñ€ÐµÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°

        Args:
            result: Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°

        Returns:
            str: Ð§ÐµÐ»Ð¾Ð²ÐµÐºÐ¾Ñ‡Ð¸Ñ‚Ð°ÐµÐ¼Ð°Ñ Ð¸Ð½Ñ‚ÐµÑ€Ð¿Ñ€ÐµÑ‚Ð°Ñ†Ð¸Ñ
        """
        data = result.data
        themes = data.get('themes', [])
        total = data.get('total_themes', 0)

        if not themes:
            return "ðŸ“– Ð¢ÐµÐ¼Ñ‹ Ð½Ðµ Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ñ‹ Ð² Ñ‚ÐµÐºÑÑ‚Ðµ."

        lines = [
            f"ðŸ“– **ÐÐ½Ð°Ð»Ð¸Ð· Ñ‚ÐµÐ¼ Ð¿Ñ€Ð¾Ð¸Ð·Ð²ÐµÐ´ÐµÐ½Ð¸Ñ**\n",
            f"ðŸ” ÐžÐ±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð¾ Ð¾ÑÐ½Ð¾Ð²Ð½Ñ‹Ñ… Ñ‚ÐµÐ¼: {total}\n"
        ]

        for i, theme in enumerate(themes, 1):
            theme_name = theme.get('theme', 'ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð°Ñ')
            frequency = theme.get('frequency', 0)
            descriptions = theme.get('descriptions', [])
            examples = theme.get('examples', [])

            lines.append(f"**{i}. {theme_name}** (Ð²ÑÑ‚Ñ€ÐµÑ‡Ð°ÐµÑ‚ÑÑ {frequency} Ñ€Ð°Ð·)")

            if descriptions:
                lines.append(f"   ðŸ’¬ {descriptions[0]}")

            if examples:
                lines.append(f"   ðŸ“ ÐŸÑ€Ð¸Ð¼ÐµÑ€: \"{examples[0][:100]}...\"")

            lines.append("")

        # Ð’Ñ‹Ð²Ð¾Ð´
        main_themes = [t.get('theme', '') for t in themes[:3]]
        lines.append(
            f"ðŸ’¡ **Ð’Ñ‹Ð²Ð¾Ð´**: ÐŸÑ€Ð¾Ð¸Ð·Ð²ÐµÐ´ÐµÐ½Ð¸Ðµ Ð¸ÑÑÐ»ÐµÐ´ÑƒÐµÑ‚ Ñ‚ÐµÐ¼Ñ‹: "
            f"{', '.join(main_themes).lower()}."
        )

        return '\n'.join(lines)

    def _create_default_prompt(self) -> PromptTemplate:
        """Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ð´ÐµÑ„Ð¾Ð»Ñ‚Ð½Ñ‹Ð¹ ÑˆÐ°Ð±Ð»Ð¾Ð½ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ð°"""
        return PromptTemplate.create_default_theme_prompt()
