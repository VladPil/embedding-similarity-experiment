"""
ÐÐ½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€ Ð½Ð°Ð¿Ñ€ÑÐ¶ÐµÐ½Ð¸Ñ (tension)
"""
import json
import re
from typing import Dict, Any, List, Optional
from loguru import logger

from ..entities.base_analyzer import BaseAnalyzer
from ..entities.analysis_result import AnalysisResult
from ..entities.prompt_template import PromptTemplate
from ..helpers.chunk_indexer import ChunkIndexer
from src.text_domain.entities.base_text import BaseText
from src.common.types import AnalysisMode
from src.common.exceptions import AnalysisError


class TensionAnalyzer(BaseAnalyzer):
    """
    ÐÐ½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€ Ð½Ð°Ð¿Ñ€ÑÐ¶ÐµÐ½Ð¸Ñ Ð² Ð¿Ñ€Ð¾Ð¸Ð·Ð²ÐµÐ´ÐµÐ½Ð¸Ð¸

    ÐÐ°Ñ…Ð¾Ð´Ð¸Ñ‚ Ð¿Ð¸ÐºÐ¸ Ð½Ð°Ð¿Ñ€ÑÐ¶ÐµÐ½Ð¸Ñ Ð¸ ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ timeline

    Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚:
    - ChunkIndexer Ð´Ð»Ñ Ð¾Ñ‚Ð±Ð¾Ñ€Ð° Ð½Ð°Ð¿Ñ€ÑÐ¶Ñ‘Ð½Ð½Ñ‹Ñ… Ñ‡Ð°Ð½ÐºÐ¾Ð²
    - LLM Ð´Ð»Ñ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ñ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¾Ð² Ð½Ð°Ð¿Ñ€ÑÐ¶ÐµÐ½Ð¸Ñ
    - ÐšÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ ÑÐ»Ð¾Ð²Ð° Ð´Ð»Ñ Ð¾Ñ†ÐµÐ½ÐºÐ¸ ÑƒÑ€Ð¾Ð²Ð½Ñ Ð½Ð°Ð¿Ñ€ÑÐ¶ÐµÐ½Ð¸Ñ

    Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚:
    - Ð¡Ñ€ÐµÐ´Ð½Ð¸Ð¹ ÑƒÑ€Ð¾Ð²ÐµÐ½ÑŒ Ð½Ð°Ð¿Ñ€ÑÐ¶ÐµÐ½Ð¸Ñ (0-10)
    - Timeline Ð½Ð°Ð¿Ñ€ÑÐ¶ÐµÐ½Ð¸Ñ
    - ÐŸÐ¸ÐºÐ¸ Ð½Ð°Ð¿Ñ€ÑÐ¶ÐµÐ½Ð¸Ñ Ñ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸ÑÐ¼Ð¸
    """

    def __init__(
        self,
        llm_service: Optional[Any] = None,
        prompt_template: Optional[PromptTemplate] = None,
        tension_threshold: float = 6.0,
        max_peaks: int = 15
    ):
        """
        Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð° Ð½Ð°Ð¿Ñ€ÑÐ¶ÐµÐ½Ð¸Ñ

        Args:
            llm_service: Ð¡ÐµÑ€Ð²Ð¸Ñ Ð´Ð»Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ñ LLM
            prompt_template: Ð¨Ð°Ð±Ð»Ð¾Ð½ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ð°
            tension_threshold: ÐŸÐ¾Ñ€Ð¾Ð³ Ð½Ð°Ð¿Ñ€ÑÐ¶ÐµÐ½Ð¸Ñ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°
            max_peaks: ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ðµ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð¸ÐºÐ¾Ð²
        """
        self.llm_service = llm_service
        self.prompt_template = prompt_template or self._create_default_prompt()
        self.tension_threshold = tension_threshold
        self.max_peaks = max_peaks
        self.indexer = ChunkIndexer()

    @property
    def requires_llm(self) -> bool:
        """Ð¢Ñ€ÐµÐ±ÑƒÐµÑ‚ÑÑ LLM Ð´Ð»Ñ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ñ Ð¿Ð¸ÐºÐ¾Ð²"""
        return True

    @property
    def requires_embeddings(self) -> bool:
        """ÐÐµ Ñ‚Ñ€ÐµÐ±ÑƒÑŽÑ‚ÑÑ embeddings"""
        return False

    async def analyze(
        self,
        text: BaseText,
        mode: AnalysisMode,
        **kwargs
    ) -> AnalysisResult:
        """
        Ð’Ñ‹Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÑŒ Ð°Ð½Ð°Ð»Ð¸Ð· Ð½Ð°Ð¿Ñ€ÑÐ¶ÐµÐ½Ð¸Ñ

        Args:
            text: Ð¢ÐµÐºÑÑ‚ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°
            mode: Ð ÐµÐ¶Ð¸Ð¼ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°
            **kwargs: Ð”Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹

        Returns:
            AnalysisResult: Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°
        """
        try:
            logger.info(f"ÐÐ°Ñ‡Ð°Ð»Ð¾ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð½Ð°Ð¿Ñ€ÑÐ¶ÐµÐ½Ð¸Ñ: {text.title}")

            # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ñ‡Ð°Ð½ÐºÐ¸
            chunks = kwargs.get('chunks', [])
            if not chunks:
                raise AnalysisError(
                    "ÐÐ½Ð°Ð»Ð¸Ð· Ð½Ð°Ð¿Ñ€ÑÐ¶ÐµÐ½Ð¸Ñ Ñ‚Ñ€ÐµÐ±ÑƒÐµÑ‚ Ñ‡Ð°Ð½ÐºÐ¸ Ñ‚ÐµÐºÑÑ‚Ð°",
                    details={"text_id": text.id}
                )

            # Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÐ¼ ÑÑ€ÐµÐ´Ð½ÐµÐµ Ð½Ð°Ð¿Ñ€ÑÐ¶ÐµÐ½Ð¸Ðµ Ð¿Ð¾ Ð²ÑÐµÐ¼ Ñ‡Ð°Ð½ÐºÐ°Ð¼
            all_scores = [
                self.indexer._calculate_tension_from_keywords(chunk.content)
                for chunk in chunks
            ]
            average_tension = sum(all_scores) / len(all_scores) if all_scores else 0.0

            # Ð¡Ñ‚Ñ€Ð¾Ð¸Ð¼ Ð¸Ð½Ð´ÐµÐºÑ Ð½Ð°Ð¿Ñ€ÑÐ¶Ñ‘Ð½Ð½Ñ‹Ñ… Ñ‡Ð°Ð½ÐºÐ¾Ð²
            tension_index = self.indexer.build_tension_index(
                chunks,
                threshold=self.tension_threshold / 10  # ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð² 0-1
            )

            logger.info(
                f"Ð˜Ð½Ð´ÐµÐºÑ Ð½Ð°Ð¿Ñ€ÑÐ¶ÐµÐ½Ð¸Ñ: {len(tension_index.chunk_indices)} Ð¿Ð¸ÐºÐ¾Ð² "
                f"({tension_index.coverage*100:.1f}% Ð¾Ñ…Ð²Ð°Ñ‚)"
            )

            # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð½Ð°Ð¿Ñ€ÑÐ¶Ñ‘Ð½Ð½Ñ‹Ðµ Ñ‡Ð°Ð½ÐºÐ¸
            tension_chunks = self.indexer.get_chunk_subset(chunks, 'tension')

            if not tension_chunks:
                logger.info("ÐÐµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ Ð¿Ð¸ÐºÐ¾Ð² Ð½Ð°Ð¿Ñ€ÑÐ¶ÐµÐ½Ð¸Ñ")
                return AnalysisResult(
                    analyzer_type=self.__class__.__name__,
                    text_id=text.id,
                    mode=mode,
                    data={
                        "average_tension": round(average_tension, 2),
                        "timeline": [],
                        "peaks": [],
                        "peak_count": 0,
                        "analysis_coverage": 0.0
                    }
                )

            # ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ Ð¿Ð¸ÐºÐ¸ Ñ LLM
            tension_points = await self._analyze_peaks_with_llm(
                tension_chunks,
                tension_index
            )

            logger.info(f"ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¾ {len(tension_points)} Ð¿Ð¸ÐºÐ¾Ð² Ð½Ð°Ð¿Ñ€ÑÐ¶ÐµÐ½Ð¸Ñ")

            return AnalysisResult(
                analyzer_type=self.__class__.__name__,
                text_id=text.id,
                mode=mode,
                data={
                    "average_tension": round(average_tension, 2),
                    "timeline": tension_points,
                    "peaks": [p['position'] for p in tension_points],
                    "peak_count": len(tension_points),
                    "analysis_coverage": tension_index.coverage
                }
            )

        except Exception as e:
            logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð½Ð°Ð¿Ñ€ÑÐ¶ÐµÐ½Ð¸Ñ: {e}")
            raise AnalysisError(
                f"ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ñ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð½Ð°Ð¿Ñ€ÑÐ¶ÐµÐ½Ð¸Ðµ: {str(e)}",
                details={"text_id": text.id}
            )

    async def _analyze_peaks_with_llm(
        self,
        chunks: List[Any],
        tension_index: Any
    ) -> List[Dict[str, Any]]:
        """
        ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¿Ð¸ÐºÐ¸ Ð½Ð°Ð¿Ñ€ÑÐ¶ÐµÐ½Ð¸Ñ Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ LLM

        Args:
            chunks: Ð¡Ð¿Ð¸ÑÐ¾Ðº Ð½Ð°Ð¿Ñ€ÑÐ¶Ñ‘Ð½Ð½Ñ‹Ñ… Ñ‡Ð°Ð½ÐºÐ¾Ð²
            tension_index: Ð˜Ð½Ð´ÐµÐºÑ Ð½Ð°Ð¿Ñ€ÑÐ¶ÐµÐ½Ð¸Ñ

        Returns:
            List[Dict]: Ð¡Ð¿Ð¸ÑÐ¾Ðº Ñ‚Ð¾Ñ‡ÐµÐº Ð½Ð°Ð¿Ñ€ÑÐ¶ÐµÐ½Ð¸Ñ
        """
        tension_points = []

        # ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡Ð¸Ð²Ð°ÐµÐ¼ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð¸ÐºÐ¾Ð²
        chunks_to_process = chunks[:self.max_peaks]

        for chunk in chunks_to_process:
            try:
                # Ð¤Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐµÐ¼ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚
                prompt = self._format_tension_prompt(chunk.content)

                # LLM Ð·Ð°Ð¿Ñ€Ð¾Ñ
                result = await self.llm_service.generate(
                    prompt=prompt,
                    max_tokens=256,
                    temperature=0.3
                )

                # ÐŸÐ°Ñ€ÑÐ¸Ð¼ Ð¾Ñ‚Ð²ÐµÑ‚
                tension_data = self._parse_tension_response(result)

                if tension_data:
                    # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ score Ð¸Ð· Ð¸Ð½Ð´ÐµÐºÑÐ°
                    chunk_idx_in_index = tension_index.chunk_indices.index(chunk.index)
                    score = tension_index.scores[chunk_idx_in_index]

                    tension_point = {
                        "position": chunk.metadata.get('position_ratio', 0.0),
                        "score": round(score, 2),
                        "source": tension_data.get('source', 'unknown'),
                        "description": tension_data.get('description', ''),
                        "excerpt": tension_data.get('excerpt', chunk.content[:200])
                    }

                    tension_points.append(tension_point)

            except Exception as e:
                logger.warning(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð¿Ð¸ÐºÐ° Ð² Ñ‡Ð°Ð½ÐºÐµ {chunk.index}: {e}")
                continue

        # Ð¡Ð¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð¿Ð¾ Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¸
        tension_points.sort(key=lambda x: x['position'])

        return tension_points

    def _format_tension_prompt(self, chunk_text: str) -> str:
        """
        Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð½Ð°Ð¿Ñ€ÑÐ¶ÐµÐ½Ð¸Ñ

        Args:
            chunk_text: Ð¢ÐµÐºÑÑ‚ Ñ‡Ð°Ð½ÐºÐ°

        Returns:
            str: ÐžÑ‚Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚
        """
        prompt = f"""ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐ¹ Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚ Ñ‚ÐµÐºÑÑ‚Ð° Ð¸ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»Ð¸ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº Ð½Ð°Ð¿Ñ€ÑÐ¶ÐµÐ½Ð¸Ñ.

Ð¤Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚:
{chunk_text[:1000]}

Ð—Ð°Ð´Ð°Ñ‡Ð°:
1. ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»Ð¸ Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº Ð½Ð°Ð¿Ñ€ÑÐ¶ÐµÐ½Ð¸Ñ: conflict (ÐºÐ¾Ð½Ñ„Ð»Ð¸ÐºÑ‚), danger (Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚ÑŒ), mystery (Ð·Ð°Ð³Ð°Ð´ÐºÐ°), emotion (ÑÐ¼Ð¾Ñ†Ð¸Ñ), time_pressure (Ð½ÐµÑ…Ð²Ð°Ñ‚ÐºÐ° Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸)
2. ÐšÑ€Ð°Ñ‚ÐºÐ¾ Ð¾Ð¿Ð¸ÑˆÐ¸ (1-2 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ), Ñ‡Ñ‚Ð¾ ÑÐ¾Ð·Ð´Ð°Ñ‘Ñ‚ Ð½Ð°Ð¿Ñ€ÑÐ¶ÐµÐ½Ð¸Ðµ
3. ÐŸÑ€Ð¸Ð²ÐµÐ´Ð¸ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÑƒÑŽ Ñ†Ð¸Ñ‚Ð°Ñ‚Ñƒ-Ð´Ð¾ÐºÐ°Ð·Ð°Ñ‚ÐµÐ»ÑŒÑÑ‚Ð²Ð¾ (Ð´Ð¾ 50 ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð²)

ÐžÑ‚Ð²ÐµÑ‚ÑŒ Ð¡Ð¢Ð ÐžÐ“Ðž Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ JSON:
{{
    "source": "conflict|danger|mystery|emotion|time_pressure",
    "description": "ÐºÑ€Ð°Ñ‚ÐºÐ¾Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ",
    "excerpt": "Ñ†Ð¸Ñ‚Ð°Ñ‚Ð° Ð¸Ð· Ñ‚ÐµÐºÑÑ‚Ð°"
}}

JSON:"""

        return prompt

    def _parse_tension_response(self, llm_response: str) -> Dict[str, Any]:
        """
        Ð Ð°ÑÐ¿Ð°Ñ€ÑÐ¸Ñ‚ÑŒ Ð¾Ñ‚Ð²ÐµÑ‚ LLM

        Args:
            llm_response: ÐžÑ‚Ð²ÐµÑ‚ LLM

        Returns:
            Dict: Ð”Ð°Ð½Ð½Ñ‹Ðµ Ð½Ð°Ð¿Ñ€ÑÐ¶ÐµÐ½Ð¸Ñ
        """
        try:
            # Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ JSON
            json_match = re.search(r'\{[^{}]*\}', llm_response, re.DOTALL)

            if json_match:
                parsed = json.loads(json_match.group(0))
                return parsed

            return {}

        except Exception as e:
            logger.warning(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ð° Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð½Ð°Ð¿Ñ€ÑÐ¶ÐµÐ½Ð¸Ñ: {e}")
            return {}

    def interpret_results(self, result: AnalysisResult) -> str:
        """
        Ð˜Ð½Ñ‚ÐµÑ€Ð¿Ñ€ÐµÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°

        Args:
            result: Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°

        Returns:
            str: Ð§ÐµÐ»Ð¾Ð²ÐµÐºÐ¾Ñ‡Ð¸Ñ‚Ð°ÐµÐ¼Ð°Ñ Ð¸Ð½Ñ‚ÐµÑ€Ð¿Ñ€ÐµÑ‚Ð°Ñ†Ð¸Ñ
        """
        data = result.data
        avg_tension = data.get('average_tension', 0)
        timeline = data.get('timeline', [])
        peak_count = data.get('peak_count', 0)

        # Ð­Ð¼Ð¾Ð´Ð·Ð¸ Ð² Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ Ð¾Ñ‚ ÑƒÑ€Ð¾Ð²Ð½Ñ
        if avg_tension > 7:
            tension_emoji = 'ðŸ”¥'
            tension_level = 'Ð¾Ñ‡ÐµÐ½ÑŒ Ð²Ñ‹ÑÐ¾ÐºÐ¾Ðµ'
        elif avg_tension > 5:
            tension_emoji = 'âš¡'
            tension_level = 'Ð²Ñ‹ÑÐ¾ÐºÐ¾Ðµ'
        elif avg_tension > 3:
            tension_emoji = 'ðŸ“Š'
            tension_level = 'ÑƒÐ¼ÐµÑ€ÐµÐ½Ð½Ð¾Ðµ'
        else:
            tension_emoji = 'ðŸŒŠ'
            tension_level = 'Ð½Ð¸Ð·ÐºÐ¾Ðµ'

        lines = [
            f"ðŸŽ­ **ÐÐ½Ð°Ð»Ð¸Ð· Ð½Ð°Ð¿Ñ€ÑÐ¶ÐµÐ½Ð¸Ñ Ð² Ð¿Ñ€Ð¾Ð¸Ð·Ð²ÐµÐ´ÐµÐ½Ð¸Ð¸**\n",
            f"{tension_emoji} **Ð¡Ñ€ÐµÐ´Ð½ÐµÐµ Ð½Ð°Ð¿Ñ€ÑÐ¶ÐµÐ½Ð¸Ðµ**: {tension_level} ({avg_tension:.1f}/10)",
            f"ðŸ“ˆ **ÐžÐ±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð¾ Ð¿Ð¸ÐºÐ¾Ð² Ð½Ð°Ð¿Ñ€ÑÐ¶ÐµÐ½Ð¸Ñ**: {peak_count}\n"
        ]

        # Timeline
        if timeline:
            lines.append(f"ðŸ“Š **Ð”Ð¸Ð½Ð°Ð¼Ð¸ÐºÐ° Ð½Ð°Ð¿Ñ€ÑÐ¶ÐµÐ½Ð¸Ñ**:\n")

            for i, point in enumerate(timeline[:5], 1):
                position = point.get('position', 0) * 100
                score = point.get('score', 0)
                source = point.get('source', 'unknown')
                description = point.get('description', '')[:80]

                lines.append(
                    f"\n   {i}. ÐÐ° {position:.0f}% Ñ‚ÐµÐºÑÑ‚Ð° (Ð½Ð°Ð¿Ñ€ÑÐ¶ÐµÐ½Ð¸Ðµ: {score:.1f}/10)\n"
                    f"      Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº: {source}\n"
                    f"      {description}..."
                )

        return '\n'.join(lines)

    def _create_default_prompt(self) -> PromptTemplate:
        """Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ð´ÐµÑ„Ð¾Ð»Ñ‚Ð½Ñ‹Ð¹ ÑˆÐ°Ð±Ð»Ð¾Ð½ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ð°"""
        return PromptTemplate.create_default_tension_prompt()
