"""
–°–µ—Ä–≤–∏—Å –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞
"""
from typing import Optional, List
from pathlib import Path
from loguru import logger
import zipfile

from ..exporters.json_exporter import JSONExporter
from ..exporters.csv_exporter import CSVExporter
from ..exporters.pdf_exporter import PDFExporter
from src.analysis_domain.entities.analysis_session import AnalysisSession
from src.analysis_domain.entities.comparison_matrix import ComparisonMatrix
from src.common.exceptions import ExportError


class ExportService:
    """
    –°–µ—Ä–≤–∏—Å –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ –≤ —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã

    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —ç–∫—Å–ø–æ—Ä—Ç –≤ JSON, CSV, PDF, Markdown
    """

    def __init__(self, output_dir: Optional[str] = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞

        Args:
            output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤
        """
        self.output_dir = output_dir or "./data/exports"

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —ç–∫—Å–ø–æ—Ä—Ç—ë—Ä—ã
        self.json_exporter = JSONExporter(output_dir=self.output_dir)
        self.csv_exporter = CSVExporter(output_dir=self.output_dir)
        self.pdf_exporter = PDFExporter(output_dir=self.output_dir)

    async def export_session(
        self,
        session: AnalysisSession,
        format: str = "json",
        file_path: Optional[str] = None,
        **kwargs
    ) -> str:
        """
        –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–µ—Å—Å–∏—é –≤ —É–∫–∞–∑–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç

        Args:
            session: –°–µ—Å—Å–∏—è –∞–Ω–∞–ª–∏–∑–∞
            format: –§–æ—Ä–º–∞—Ç —ç–∫—Å–ø–æ—Ä—Ç–∞ (json, csv, pdf, markdown)
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã

        Returns:
            str: –ü—É—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É

        Raises:
            ExportError: –ï—Å–ª–∏ —Ñ–æ—Ä–º–∞—Ç –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –∏–ª–∏ –æ—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞
        """
        try:
            if format == "json":
                return await self.json_exporter.export_session(session, file_path)
            elif format == "csv":
                return await self.csv_exporter.export_session(session, file_path)
            elif format == "pdf":
                return await self.pdf_exporter.export_session(session, file_path)
            elif format == "markdown":
                return await self.export_session_markdown(session, file_path)
            else:
                raise ExportError(
                    message=f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —ç–∫—Å–ø–æ—Ä—Ç–∞: {format}",
                    details={"supported_formats": ["json", "csv", "pdf", "markdown"]}
                )
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ —Å–µ—Å—Å–∏–∏ –≤ {format}: {e}")
            raise ExportError(
                message=f"–ù–µ —É–¥–∞–ª–æ—Å—å —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–µ—Å—Å–∏—é –≤ {format}",
                details={"error": str(e), "session_id": session.id}
            )

    async def export_comparison_matrix(
        self,
        matrix: ComparisonMatrix,
        format: str = "json",
        file_path: Optional[str] = None
    ) -> str:
        """
        –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –º–∞—Ç—Ä–∏—Ü—É —Å—Ä–∞–≤–Ω–µ–Ω–∏—è

        Args:
            matrix: –ú–∞—Ç—Ä–∏—Ü–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            format: –§–æ—Ä–º–∞—Ç —ç–∫—Å–ø–æ—Ä—Ç–∞
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É

        Returns:
            str: –ü—É—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
        """
        try:
            if format == "json":
                return await self.json_exporter.export_comparison_matrix(matrix, file_path)
            elif format == "csv":
                return await self.csv_exporter.export_comparison_matrix(matrix, file_path)
            elif format == "pdf":
                return await self.pdf_exporter.export_comparison_matrix(matrix, file_path)
            else:
                raise ExportError(
                    message=f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç: {format}",
                    details={"supported_formats": ["json", "csv", "pdf"]}
                )
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –º–∞—Ç—Ä–∏—Ü—ã –≤ {format}: {e}")
            raise ExportError(
                message=f"–ù–µ —É–¥–∞–ª–æ—Å—å —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –º–∞—Ç—Ä–∏—Ü—É –≤ {format}",
                details={"error": str(e)}
            )

    async def export_session_markdown(
        self,
        session: AnalysisSession,
        file_path: Optional[str] = None
    ) -> str:
        """
        –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–µ—Å—Å–∏—é –≤ Markdown —Ñ–æ—Ä–º–∞—Ç

        Args:
            session: –°–µ—Å—Å–∏—è –∞–Ω–∞–ª–∏–∑–∞
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É

        Returns:
            str: –ü—É—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
        """
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—É—Ç—å –µ—Å–ª–∏ –Ω–µ –∑–∞–¥–∞–Ω
        if not file_path:
            from datetime import datetime
            safe_name = "".join(
                c if c.isalnum() or c in "._- " else "_"
                for c in session.name
            )
            ts = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"{safe_name}_{ts}.md"
            file_path = str(Path(self.output_dir) / filename)

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º Markdown –∫–æ–Ω—Ç–µ–Ω—Ç
        lines = []

        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        lines.append(f"# –û—Ç—á—ë—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É: {session.name}\n")
        lines.append(f"**ID —Å–µ—Å—Å–∏–∏:** `{session.id}`\n")
        lines.append(f"**–°—Ç–∞—Ç—É—Å:** {session.status.value}\n")
        lines.append(f"**–†–µ–∂–∏–º:** {session.mode.value}\n")
        lines.append(f"**–°–æ–∑–¥–∞–Ω–æ:** {session.created_at.strftime('%Y-%m-%d %H:%M:%S')}\n")
        if session.completed_at:
            lines.append(f"**–ó–∞–≤–µ—Ä—à–µ–Ω–æ:** {session.completed_at.strftime('%Y-%m-%d %H:%M:%S')}\n")
        lines.append("\n---\n\n")

        # –¢–µ–∫—Å—Ç—ã
        lines.append("## –¢–µ–∫—Å—Ç—ã\n\n")
        for idx, text in enumerate(session.texts, 1):
            content_len = len(await text.get_content()) if hasattr(text, 'get_content') else 0
            lines.append(f"{idx}. **{text.title}**\n")
            lines.append(f"   - ID: `{text.id}`\n")
            lines.append(f"   - –î–ª–∏–Ω–∞: {content_len:,} —Å–∏–º–≤–æ–ª–æ–≤\n\n")

        # –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä—ã
        if session.analyzers:
            lines.append("## –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä—ã\n\n")
            for analyzer in session.analyzers:
                lines.append(f"- {analyzer.__class__.__name__}")
                if analyzer.requires_llm:
                    lines.append(" *(—Ç—Ä–µ–±—É–µ—Ç LLM)*")
                lines.append("\n")
            lines.append("\n")

        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞
        if session.results:
            lines.append("## –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞\n\n")
            for text_id, result in session.results.items():
                lines.append(f"### –¢–µ–∫—Å—Ç: {text_id[:8]}...\n\n")
                lines.append(f"**–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä:** {result.analyzer_type}\n\n")
                if hasattr(result, 'data') and result.data:
                    lines.append("**–î–∞–Ω–Ω—ã–µ:**\n\n")
                    lines.append(f"```json\n{result.data}\n```\n\n")

        # –ú–∞—Ç—Ä–∏—Ü–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        if session.comparison_matrix:
            lines.append("## –ú–∞—Ç—Ä–∏—Ü–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è\n\n")
            matrix = session.comparison_matrix
            avg_sim = matrix.get_average_similarity()
            lines.append(f"**–°—Ä–µ–¥–Ω—è—è —Å—Ö–æ–∂–µ—Å—Ç—å:** {avg_sim:.4f}\n\n")

            # –¢–æ–ø –ø–æ—Ö–æ–∂–∏—Ö –ø–∞—Ä
            most_similar = matrix.get_most_similar_pairs(top_k=5)
            if most_similar:
                lines.append("### –¢–æ–ø-5 –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ—Ö–æ–∂–∏—Ö –ø–∞—Ä\n\n")
                lines.append("| ‚Ññ | –¢–µ–∫—Å—Ç 1 | –¢–µ–∫—Å—Ç 2 | –°—Ö–æ–∂–µ—Å—Ç—å |\n")
                lines.append("|---|---------|---------|----------|\n")
                for idx, pair in enumerate(most_similar, 1):
                    lines.append(
                        f"| {idx} | {pair['text1_id'][:15]}... | "
                        f"{pair['text2_id'][:15]}... | {pair['similarity']:.4f} |\n"
                    )
                lines.append("\n")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
        Path(self.output_dir).mkdir(parents=True, exist_ok=True)
        with open(file_path, 'w', encoding='utf-8') as f:
            f.writelines(lines)

        logger.info(f"üìù Markdown —ç–∫—Å–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à—ë–Ω: {file_path}")
        return file_path

    async def batch_export(
        self,
        sessions: List[AnalysisSession],
        format: str = "json",
        create_archive: bool = True
    ) -> str:
        """
        –ú–∞—Å—Å–æ–≤—ã–π —ç–∫—Å–ø–æ—Ä—Ç –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å–µ—Å—Å–∏–π

        Args:
            sessions: –°–ø–∏—Å–æ–∫ —Å–µ—Å—Å–∏–π –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞
            format: –§–æ—Ä–º–∞—Ç —ç–∫—Å–ø–æ—Ä—Ç–∞
            create_archive: –°–æ–∑–¥–∞—Ç—å ZIP –∞—Ä—Ö–∏–≤ —Å —Ñ–∞–π–ª–∞–º–∏

        Returns:
            str: –ü—É—Ç—å –∫ –∞—Ä—Ö–∏–≤—É –∏–ª–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å —Ñ–∞–π–ª–∞–º–∏
        """
        if not sessions:
            raise ExportError(
                message="–°–ø–∏—Å–æ–∫ —Å–µ—Å—Å–∏–π –ø—É—Å—Ç",
                details={}
            )

        exported_files = []

        # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é —Å–µ—Å—Å–∏—é
        for session in sessions:
            try:
                file_path = await self.export_session(session, format=format)
                exported_files.append(file_path)
            except Exception as e:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–µ—Å—Å–∏—é {session.id}: {e}")

        if not exported_files:
            raise ExportError(
                message="–ù–µ —É–¥–∞–ª–æ—Å—å —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–π —Å–µ—Å—Å–∏–∏",
                details={"total_sessions": len(sessions)}
            )

        # –°–æ–∑–¥–∞—ë–º –∞—Ä—Ö–∏–≤ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if create_archive:
            from datetime import datetime
            archive_name = f"batch_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip"
            archive_path = str(Path(self.output_dir) / archive_name)

            with zipfile.ZipFile(archive_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                for file_path in exported_files:
                    zipf.write(file_path, Path(file_path).name)

            logger.info(
                f"üì¶ –°–æ–∑–¥–∞–Ω –∞—Ä—Ö–∏–≤ —Å {len(exported_files)} —Ñ–∞–π–ª–∞–º–∏: {archive_path}"
            )
            return archive_path
        else:
            logger.info(f"‚úÖ –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {len(exported_files)} —Ñ–∞–π–ª–æ–≤")
            return self.output_dir

    def get_available_templates(self) -> List[dict]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —à–∞–±–ª–æ–Ω–æ–≤ —ç–∫—Å–ø–æ—Ä—Ç–∞

        Returns:
            List[dict]: –°–ø–∏—Å–æ–∫ —à–∞–±–ª–æ–Ω–æ–≤
        """
        return [
            {
                "id": "default",
                "name": "–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –æ—Ç—á—ë—Ç",
                "formats": ["json", "csv", "pdf", "markdown"],
                "description": "–ü–æ–ª–Ω—ã–π –æ—Ç—á—ë—Ç —Å–æ –≤—Å–µ–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞"
            },
            {
                "id": "detailed_pdf",
                "name": "–î–µ—Ç–∞–ª—å–Ω—ã–π PDF —Å –≥—Ä–∞—Ñ–∏–∫–∞–º–∏",
                "formats": ["pdf"],
                "description": "PDF –æ—Ç—á—ë—Ç —Å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è–º–∏ –∏ –ø–æ–¥—Ä–æ–±–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π"
            },
            {
                "id": "summary",
                "name": "–ö—Ä–∞—Ç–∫–∞—è —Å–≤–æ–¥–∫–∞",
                "formats": ["csv", "markdown"],
                "description": "–ö–æ–º–ø–∞–∫—Ç–Ω—ã–π –æ—Ç—á—ë—Ç —Å –æ—Å–Ω–æ–≤–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏"
            },
            {
                "id": "comparison_only",
                "name": "–¢–æ–ª—å–∫–æ –º–∞—Ç—Ä–∏—Ü–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è",
                "formats": ["json", "csv", "pdf"],
                "description": "–≠–∫—Å–ø–æ—Ä—Ç —Ç–æ–ª—å–∫–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–æ–≤"
            }
        ]

    def get_supported_formats(self) -> List[str]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤

        Returns:
            List[str]: –°–ø–∏—Å–æ–∫ —Ñ–æ—Ä–º–∞—Ç–æ–≤
        """
        return ["json", "csv", "pdf", "markdown"]
